{
  "best_metric": 2.741579532623291,
  "best_model_checkpoint": "./outputs/checkpoint-1700",
  "epoch": 0.7555555555555555,
  "eval_steps": 100,
  "global_step": 1700,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0044444444444444444,
      "grad_norm": 0.6385458707809448,
      "learning_rate": 4.9888888888888894e-05,
      "loss": 3.4474,
      "step": 10
    },
    {
      "epoch": 0.008888888888888889,
      "grad_norm": 0.5836634635925293,
      "learning_rate": 4.977777777777778e-05,
      "loss": 3.2499,
      "step": 20
    },
    {
      "epoch": 0.013333333333333334,
      "grad_norm": 0.5975626111030579,
      "learning_rate": 4.966666666666667e-05,
      "loss": 2.9499,
      "step": 30
    },
    {
      "epoch": 0.017777777777777778,
      "grad_norm": 0.5284260511398315,
      "learning_rate": 4.955555555555556e-05,
      "loss": 2.9841,
      "step": 40
    },
    {
      "epoch": 0.022222222222222223,
      "grad_norm": 0.4768317639827728,
      "learning_rate": 4.9444444444444446e-05,
      "loss": 2.8488,
      "step": 50
    },
    {
      "epoch": 0.02666666666666667,
      "grad_norm": 0.6019676923751831,
      "learning_rate": 4.933333333333334e-05,
      "loss": 2.8174,
      "step": 60
    },
    {
      "epoch": 0.03111111111111111,
      "grad_norm": 0.4315429627895355,
      "learning_rate": 4.922222222222222e-05,
      "loss": 2.8301,
      "step": 70
    },
    {
      "epoch": 0.035555555555555556,
      "grad_norm": 0.5725593566894531,
      "learning_rate": 4.9111111111111114e-05,
      "loss": 2.8291,
      "step": 80
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.5543215274810791,
      "learning_rate": 4.9e-05,
      "loss": 2.8156,
      "step": 90
    },
    {
      "epoch": 0.044444444444444446,
      "grad_norm": 0.4583193063735962,
      "learning_rate": 4.888888888888889e-05,
      "loss": 2.8502,
      "step": 100
    },
    {
      "epoch": 0.044444444444444446,
      "eval_loss": 2.8353183269500732,
      "eval_runtime": 197.5325,
      "eval_samples_per_second": 10.125,
      "eval_steps_per_second": 1.266,
      "step": 100
    },
    {
      "epoch": 0.04888888888888889,
      "grad_norm": 0.6037725210189819,
      "learning_rate": 4.8777777777777775e-05,
      "loss": 2.8819,
      "step": 110
    },
    {
      "epoch": 0.05333333333333334,
      "grad_norm": 0.6795234084129333,
      "learning_rate": 4.866666666666667e-05,
      "loss": 2.9167,
      "step": 120
    },
    {
      "epoch": 0.057777777777777775,
      "grad_norm": 0.674334704875946,
      "learning_rate": 4.855555555555556e-05,
      "loss": 2.7826,
      "step": 130
    },
    {
      "epoch": 0.06222222222222222,
      "grad_norm": 0.6613140106201172,
      "learning_rate": 4.844444444444445e-05,
      "loss": 2.8455,
      "step": 140
    },
    {
      "epoch": 0.06666666666666667,
      "grad_norm": 0.7885493040084839,
      "learning_rate": 4.8333333333333334e-05,
      "loss": 2.7365,
      "step": 150
    },
    {
      "epoch": 0.07111111111111111,
      "grad_norm": 0.8391779661178589,
      "learning_rate": 4.8222222222222225e-05,
      "loss": 2.7638,
      "step": 160
    },
    {
      "epoch": 0.07555555555555556,
      "grad_norm": 0.6468204855918884,
      "learning_rate": 4.811111111111111e-05,
      "loss": 2.7456,
      "step": 170
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.683377742767334,
      "learning_rate": 4.8e-05,
      "loss": 2.801,
      "step": 180
    },
    {
      "epoch": 0.08444444444444445,
      "grad_norm": 0.5992774963378906,
      "learning_rate": 4.7888888888888886e-05,
      "loss": 2.7839,
      "step": 190
    },
    {
      "epoch": 0.08888888888888889,
      "grad_norm": 0.6587018966674805,
      "learning_rate": 4.7777777777777784e-05,
      "loss": 2.8475,
      "step": 200
    },
    {
      "epoch": 0.08888888888888889,
      "eval_loss": 2.8036391735076904,
      "eval_runtime": 197.5629,
      "eval_samples_per_second": 10.123,
      "eval_steps_per_second": 1.265,
      "step": 200
    },
    {
      "epoch": 0.09333333333333334,
      "grad_norm": 0.6106796860694885,
      "learning_rate": 4.766666666666667e-05,
      "loss": 2.702,
      "step": 210
    },
    {
      "epoch": 0.09777777777777778,
      "grad_norm": 1.0709853172302246,
      "learning_rate": 4.755555555555556e-05,
      "loss": 2.6563,
      "step": 220
    },
    {
      "epoch": 0.10222222222222223,
      "grad_norm": 0.766156792640686,
      "learning_rate": 4.7444444444444445e-05,
      "loss": 2.7211,
      "step": 230
    },
    {
      "epoch": 0.10666666666666667,
      "grad_norm": 0.7021797895431519,
      "learning_rate": 4.7333333333333336e-05,
      "loss": 2.7997,
      "step": 240
    },
    {
      "epoch": 0.1111111111111111,
      "grad_norm": 0.7881563305854797,
      "learning_rate": 4.722222222222222e-05,
      "loss": 2.7492,
      "step": 250
    },
    {
      "epoch": 0.11555555555555555,
      "grad_norm": 0.7008208632469177,
      "learning_rate": 4.711111111111111e-05,
      "loss": 2.7347,
      "step": 260
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5889718532562256,
      "learning_rate": 4.7e-05,
      "loss": 2.7529,
      "step": 270
    },
    {
      "epoch": 0.12444444444444444,
      "grad_norm": 0.7305594682693481,
      "learning_rate": 4.6888888888888895e-05,
      "loss": 2.7243,
      "step": 280
    },
    {
      "epoch": 0.1288888888888889,
      "grad_norm": 0.7315137386322021,
      "learning_rate": 4.677777777777778e-05,
      "loss": 2.7451,
      "step": 290
    },
    {
      "epoch": 0.13333333333333333,
      "grad_norm": 0.7913298606872559,
      "learning_rate": 4.666666666666667e-05,
      "loss": 2.7776,
      "step": 300
    },
    {
      "epoch": 0.13333333333333333,
      "eval_loss": 2.788290500640869,
      "eval_runtime": 197.4899,
      "eval_samples_per_second": 10.127,
      "eval_steps_per_second": 1.266,
      "step": 300
    },
    {
      "epoch": 0.13777777777777778,
      "grad_norm": 0.672248125076294,
      "learning_rate": 4.6555555555555556e-05,
      "loss": 2.8238,
      "step": 310
    },
    {
      "epoch": 0.14222222222222222,
      "grad_norm": 0.6893551349639893,
      "learning_rate": 4.644444444444445e-05,
      "loss": 2.7119,
      "step": 320
    },
    {
      "epoch": 0.14666666666666667,
      "grad_norm": 0.7400459051132202,
      "learning_rate": 4.633333333333333e-05,
      "loss": 2.7798,
      "step": 330
    },
    {
      "epoch": 0.1511111111111111,
      "grad_norm": 1.0300168991088867,
      "learning_rate": 4.6222222222222224e-05,
      "loss": 2.7234,
      "step": 340
    },
    {
      "epoch": 0.15555555555555556,
      "grad_norm": 0.622245192527771,
      "learning_rate": 4.6111111111111115e-05,
      "loss": 2.7447,
      "step": 350
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.749061644077301,
      "learning_rate": 4.600000000000001e-05,
      "loss": 2.7392,
      "step": 360
    },
    {
      "epoch": 0.16444444444444445,
      "grad_norm": 1.0893040895462036,
      "learning_rate": 4.588888888888889e-05,
      "loss": 2.871,
      "step": 370
    },
    {
      "epoch": 0.1688888888888889,
      "grad_norm": 0.7031847834587097,
      "learning_rate": 4.577777777777778e-05,
      "loss": 2.7384,
      "step": 380
    },
    {
      "epoch": 0.17333333333333334,
      "grad_norm": 0.9796207547187805,
      "learning_rate": 4.566666666666667e-05,
      "loss": 2.7469,
      "step": 390
    },
    {
      "epoch": 0.17777777777777778,
      "grad_norm": 1.1894820928573608,
      "learning_rate": 4.555555555555556e-05,
      "loss": 2.7717,
      "step": 400
    },
    {
      "epoch": 0.17777777777777778,
      "eval_loss": 2.782315254211426,
      "eval_runtime": 197.5715,
      "eval_samples_per_second": 10.123,
      "eval_steps_per_second": 1.265,
      "step": 400
    },
    {
      "epoch": 0.18222222222222223,
      "grad_norm": 0.9657090902328491,
      "learning_rate": 4.5444444444444444e-05,
      "loss": 2.7223,
      "step": 410
    },
    {
      "epoch": 0.18666666666666668,
      "grad_norm": 0.9215372204780579,
      "learning_rate": 4.5333333333333335e-05,
      "loss": 2.801,
      "step": 420
    },
    {
      "epoch": 0.19111111111111112,
      "grad_norm": 0.8388105034828186,
      "learning_rate": 4.522222222222223e-05,
      "loss": 2.7478,
      "step": 430
    },
    {
      "epoch": 0.19555555555555557,
      "grad_norm": 0.8535682559013367,
      "learning_rate": 4.511111111111112e-05,
      "loss": 2.6471,
      "step": 440
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.9995908141136169,
      "learning_rate": 4.5e-05,
      "loss": 2.6696,
      "step": 450
    },
    {
      "epoch": 0.20444444444444446,
      "grad_norm": 0.701619029045105,
      "learning_rate": 4.4888888888888894e-05,
      "loss": 2.6829,
      "step": 460
    },
    {
      "epoch": 0.2088888888888889,
      "grad_norm": 0.7900257706642151,
      "learning_rate": 4.477777777777778e-05,
      "loss": 2.7647,
      "step": 470
    },
    {
      "epoch": 0.21333333333333335,
      "grad_norm": 0.7405385375022888,
      "learning_rate": 4.466666666666667e-05,
      "loss": 2.7003,
      "step": 480
    },
    {
      "epoch": 0.21777777777777776,
      "grad_norm": 0.7802812457084656,
      "learning_rate": 4.4555555555555555e-05,
      "loss": 2.7491,
      "step": 490
    },
    {
      "epoch": 0.2222222222222222,
      "grad_norm": 0.7782845497131348,
      "learning_rate": 4.4444444444444447e-05,
      "loss": 2.8225,
      "step": 500
    },
    {
      "epoch": 0.2222222222222222,
      "eval_loss": 2.7725062370300293,
      "eval_runtime": 197.2198,
      "eval_samples_per_second": 10.141,
      "eval_steps_per_second": 1.268,
      "step": 500
    },
    {
      "epoch": 0.22666666666666666,
      "grad_norm": 0.6806333661079407,
      "learning_rate": 4.433333333333334e-05,
      "loss": 2.7608,
      "step": 510
    },
    {
      "epoch": 0.2311111111111111,
      "grad_norm": 0.6650264263153076,
      "learning_rate": 4.422222222222222e-05,
      "loss": 2.8454,
      "step": 520
    },
    {
      "epoch": 0.23555555555555555,
      "grad_norm": 0.647793710231781,
      "learning_rate": 4.4111111111111114e-05,
      "loss": 2.8493,
      "step": 530
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.7477841377258301,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 2.6885,
      "step": 540
    },
    {
      "epoch": 0.24444444444444444,
      "grad_norm": 0.6355180740356445,
      "learning_rate": 4.388888888888889e-05,
      "loss": 2.7658,
      "step": 550
    },
    {
      "epoch": 0.24888888888888888,
      "grad_norm": 0.743603527545929,
      "learning_rate": 4.377777777777778e-05,
      "loss": 2.7571,
      "step": 560
    },
    {
      "epoch": 0.25333333333333335,
      "grad_norm": 0.7004106044769287,
      "learning_rate": 4.3666666666666666e-05,
      "loss": 2.73,
      "step": 570
    },
    {
      "epoch": 0.2577777777777778,
      "grad_norm": 0.8036758303642273,
      "learning_rate": 4.355555555555556e-05,
      "loss": 2.7492,
      "step": 580
    },
    {
      "epoch": 0.26222222222222225,
      "grad_norm": 0.9417545199394226,
      "learning_rate": 4.344444444444445e-05,
      "loss": 2.726,
      "step": 590
    },
    {
      "epoch": 0.26666666666666666,
      "grad_norm": 0.8402337431907654,
      "learning_rate": 4.3333333333333334e-05,
      "loss": 2.674,
      "step": 600
    },
    {
      "epoch": 0.26666666666666666,
      "eval_loss": 2.7687604427337646,
      "eval_runtime": 197.1542,
      "eval_samples_per_second": 10.144,
      "eval_steps_per_second": 1.268,
      "step": 600
    },
    {
      "epoch": 0.27111111111111114,
      "grad_norm": 0.7417306900024414,
      "learning_rate": 4.3222222222222226e-05,
      "loss": 2.7678,
      "step": 610
    },
    {
      "epoch": 0.27555555555555555,
      "grad_norm": 1.0891952514648438,
      "learning_rate": 4.311111111111111e-05,
      "loss": 2.7515,
      "step": 620
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.6318672895431519,
      "learning_rate": 4.3e-05,
      "loss": 2.8414,
      "step": 630
    },
    {
      "epoch": 0.28444444444444444,
      "grad_norm": 0.9144419431686401,
      "learning_rate": 4.2888888888888886e-05,
      "loss": 2.6959,
      "step": 640
    },
    {
      "epoch": 0.28888888888888886,
      "grad_norm": 0.7177309989929199,
      "learning_rate": 4.277777777777778e-05,
      "loss": 2.7571,
      "step": 650
    },
    {
      "epoch": 0.29333333333333333,
      "grad_norm": 0.788387656211853,
      "learning_rate": 4.266666666666667e-05,
      "loss": 2.7638,
      "step": 660
    },
    {
      "epoch": 0.29777777777777775,
      "grad_norm": 0.8486708998680115,
      "learning_rate": 4.255555555555556e-05,
      "loss": 2.6516,
      "step": 670
    },
    {
      "epoch": 0.3022222222222222,
      "grad_norm": 0.7327678799629211,
      "learning_rate": 4.2444444444444445e-05,
      "loss": 2.7269,
      "step": 680
    },
    {
      "epoch": 0.30666666666666664,
      "grad_norm": 0.8359125852584839,
      "learning_rate": 4.233333333333334e-05,
      "loss": 2.8246,
      "step": 690
    },
    {
      "epoch": 0.3111111111111111,
      "grad_norm": 0.7560226917266846,
      "learning_rate": 4.222222222222222e-05,
      "loss": 2.7814,
      "step": 700
    },
    {
      "epoch": 0.3111111111111111,
      "eval_loss": 2.7650961875915527,
      "eval_runtime": 198.6402,
      "eval_samples_per_second": 10.068,
      "eval_steps_per_second": 1.259,
      "step": 700
    },
    {
      "epoch": 0.31555555555555553,
      "grad_norm": 1.067901849746704,
      "learning_rate": 4.211111111111111e-05,
      "loss": 2.7116,
      "step": 710
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.9432044625282288,
      "learning_rate": 4.2e-05,
      "loss": 2.6898,
      "step": 720
    },
    {
      "epoch": 0.3244444444444444,
      "grad_norm": 0.8957403302192688,
      "learning_rate": 4.188888888888889e-05,
      "loss": 2.7443,
      "step": 730
    },
    {
      "epoch": 0.3288888888888889,
      "grad_norm": 0.6469542980194092,
      "learning_rate": 4.177777777777778e-05,
      "loss": 2.6894,
      "step": 740
    },
    {
      "epoch": 0.3333333333333333,
      "grad_norm": 0.8531420826911926,
      "learning_rate": 4.166666666666667e-05,
      "loss": 2.7056,
      "step": 750
    },
    {
      "epoch": 0.3377777777777778,
      "grad_norm": 0.8999106287956238,
      "learning_rate": 4.155555555555556e-05,
      "loss": 2.6939,
      "step": 760
    },
    {
      "epoch": 0.3422222222222222,
      "grad_norm": 0.7439743876457214,
      "learning_rate": 4.144444444444445e-05,
      "loss": 2.7058,
      "step": 770
    },
    {
      "epoch": 0.3466666666666667,
      "grad_norm": 0.8376057147979736,
      "learning_rate": 4.133333333333333e-05,
      "loss": 2.8228,
      "step": 780
    },
    {
      "epoch": 0.3511111111111111,
      "grad_norm": 0.8972124457359314,
      "learning_rate": 4.1222222222222224e-05,
      "loss": 2.8116,
      "step": 790
    },
    {
      "epoch": 0.35555555555555557,
      "grad_norm": 0.8277852535247803,
      "learning_rate": 4.111111111111111e-05,
      "loss": 2.6769,
      "step": 800
    },
    {
      "epoch": 0.35555555555555557,
      "eval_loss": 2.7616944313049316,
      "eval_runtime": 198.6423,
      "eval_samples_per_second": 10.068,
      "eval_steps_per_second": 1.259,
      "step": 800
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.7409864664077759,
      "learning_rate": 4.1e-05,
      "loss": 2.7243,
      "step": 810
    },
    {
      "epoch": 0.36444444444444446,
      "grad_norm": 0.7423574924468994,
      "learning_rate": 4.088888888888889e-05,
      "loss": 2.8037,
      "step": 820
    },
    {
      "epoch": 0.3688888888888889,
      "grad_norm": 0.8455179333686829,
      "learning_rate": 4.0777777777777783e-05,
      "loss": 2.9172,
      "step": 830
    },
    {
      "epoch": 0.37333333333333335,
      "grad_norm": 0.7147595286369324,
      "learning_rate": 4.066666666666667e-05,
      "loss": 2.7305,
      "step": 840
    },
    {
      "epoch": 0.37777777777777777,
      "grad_norm": 1.0532411336898804,
      "learning_rate": 4.055555555555556e-05,
      "loss": 2.7317,
      "step": 850
    },
    {
      "epoch": 0.38222222222222224,
      "grad_norm": 4.514044284820557,
      "learning_rate": 4.0444444444444444e-05,
      "loss": 2.8281,
      "step": 860
    },
    {
      "epoch": 0.38666666666666666,
      "grad_norm": 0.7768872976303101,
      "learning_rate": 4.0333333333333336e-05,
      "loss": 2.8237,
      "step": 870
    },
    {
      "epoch": 0.39111111111111113,
      "grad_norm": 0.7565159797668457,
      "learning_rate": 4.022222222222222e-05,
      "loss": 2.7731,
      "step": 880
    },
    {
      "epoch": 0.39555555555555555,
      "grad_norm": 0.8025693893432617,
      "learning_rate": 4.011111111111111e-05,
      "loss": 2.6645,
      "step": 890
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.6811626553535461,
      "learning_rate": 4e-05,
      "loss": 2.7047,
      "step": 900
    },
    {
      "epoch": 0.4,
      "eval_loss": 2.7587039470672607,
      "eval_runtime": 196.7503,
      "eval_samples_per_second": 10.165,
      "eval_steps_per_second": 1.271,
      "step": 900
    },
    {
      "epoch": 0.40444444444444444,
      "grad_norm": 0.9500214457511902,
      "learning_rate": 3.9888888888888895e-05,
      "loss": 2.8124,
      "step": 910
    },
    {
      "epoch": 0.4088888888888889,
      "grad_norm": 0.7919833064079285,
      "learning_rate": 3.977777777777778e-05,
      "loss": 2.7481,
      "step": 920
    },
    {
      "epoch": 0.41333333333333333,
      "grad_norm": 0.8032611608505249,
      "learning_rate": 3.966666666666667e-05,
      "loss": 2.816,
      "step": 930
    },
    {
      "epoch": 0.4177777777777778,
      "grad_norm": 1.011407494544983,
      "learning_rate": 3.9555555555555556e-05,
      "loss": 2.6621,
      "step": 940
    },
    {
      "epoch": 0.4222222222222222,
      "grad_norm": 0.9008998870849609,
      "learning_rate": 3.944444444444445e-05,
      "loss": 2.74,
      "step": 950
    },
    {
      "epoch": 0.4266666666666667,
      "grad_norm": 1.185471534729004,
      "learning_rate": 3.933333333333333e-05,
      "loss": 2.6981,
      "step": 960
    },
    {
      "epoch": 0.4311111111111111,
      "grad_norm": 1.201636552810669,
      "learning_rate": 3.922222222222223e-05,
      "loss": 2.7555,
      "step": 970
    },
    {
      "epoch": 0.43555555555555553,
      "grad_norm": 0.8024631142616272,
      "learning_rate": 3.9111111111111115e-05,
      "loss": 2.7641,
      "step": 980
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6904645562171936,
      "learning_rate": 3.9000000000000006e-05,
      "loss": 2.6611,
      "step": 990
    },
    {
      "epoch": 0.4444444444444444,
      "grad_norm": 0.7890646457672119,
      "learning_rate": 3.888888888888889e-05,
      "loss": 2.7008,
      "step": 1000
    },
    {
      "epoch": 0.4444444444444444,
      "eval_loss": 2.756218194961548,
      "eval_runtime": 197.5331,
      "eval_samples_per_second": 10.125,
      "eval_steps_per_second": 1.266,
      "step": 1000
    },
    {
      "epoch": 0.4488888888888889,
      "grad_norm": 0.890580952167511,
      "learning_rate": 3.877777777777778e-05,
      "loss": 2.7164,
      "step": 1010
    },
    {
      "epoch": 0.4533333333333333,
      "grad_norm": 0.8256881833076477,
      "learning_rate": 3.866666666666667e-05,
      "loss": 2.7487,
      "step": 1020
    },
    {
      "epoch": 0.4577777777777778,
      "grad_norm": 0.8078989386558533,
      "learning_rate": 3.855555555555556e-05,
      "loss": 2.7375,
      "step": 1030
    },
    {
      "epoch": 0.4622222222222222,
      "grad_norm": 0.8892345428466797,
      "learning_rate": 3.844444444444444e-05,
      "loss": 2.6949,
      "step": 1040
    },
    {
      "epoch": 0.4666666666666667,
      "grad_norm": 0.8739168643951416,
      "learning_rate": 3.8333333333333334e-05,
      "loss": 2.751,
      "step": 1050
    },
    {
      "epoch": 0.4711111111111111,
      "grad_norm": 0.8137445449829102,
      "learning_rate": 3.8222222222222226e-05,
      "loss": 2.7603,
      "step": 1060
    },
    {
      "epoch": 0.47555555555555556,
      "grad_norm": 1.027011513710022,
      "learning_rate": 3.811111111111112e-05,
      "loss": 2.7133,
      "step": 1070
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.7454120516777039,
      "learning_rate": 3.8e-05,
      "loss": 2.7783,
      "step": 1080
    },
    {
      "epoch": 0.48444444444444446,
      "grad_norm": 0.7455510497093201,
      "learning_rate": 3.7888888888888894e-05,
      "loss": 2.6809,
      "step": 1090
    },
    {
      "epoch": 0.4888888888888889,
      "grad_norm": 0.9306420087814331,
      "learning_rate": 3.777777777777778e-05,
      "loss": 2.6699,
      "step": 1100
    },
    {
      "epoch": 0.4888888888888889,
      "eval_loss": 2.754688024520874,
      "eval_runtime": 197.4911,
      "eval_samples_per_second": 10.127,
      "eval_steps_per_second": 1.266,
      "step": 1100
    },
    {
      "epoch": 0.49333333333333335,
      "grad_norm": 0.7359369397163391,
      "learning_rate": 3.766666666666667e-05,
      "loss": 2.6942,
      "step": 1110
    },
    {
      "epoch": 0.49777777777777776,
      "grad_norm": 0.7743101716041565,
      "learning_rate": 3.7555555555555554e-05,
      "loss": 2.7639,
      "step": 1120
    },
    {
      "epoch": 0.5022222222222222,
      "grad_norm": 0.8032435774803162,
      "learning_rate": 3.7444444444444446e-05,
      "loss": 2.7723,
      "step": 1130
    },
    {
      "epoch": 0.5066666666666667,
      "grad_norm": 0.9717305898666382,
      "learning_rate": 3.733333333333334e-05,
      "loss": 2.6971,
      "step": 1140
    },
    {
      "epoch": 0.5111111111111111,
      "grad_norm": 0.9070069193840027,
      "learning_rate": 3.722222222222222e-05,
      "loss": 2.7381,
      "step": 1150
    },
    {
      "epoch": 0.5155555555555555,
      "grad_norm": 0.9354702234268188,
      "learning_rate": 3.7111111111111113e-05,
      "loss": 2.7848,
      "step": 1160
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.8274703621864319,
      "learning_rate": 3.7e-05,
      "loss": 2.6586,
      "step": 1170
    },
    {
      "epoch": 0.5244444444444445,
      "grad_norm": 0.6774625778198242,
      "learning_rate": 3.688888888888889e-05,
      "loss": 2.7436,
      "step": 1180
    },
    {
      "epoch": 0.5288888888888889,
      "grad_norm": 0.8063578605651855,
      "learning_rate": 3.677777777777778e-05,
      "loss": 2.7168,
      "step": 1190
    },
    {
      "epoch": 0.5333333333333333,
      "grad_norm": 0.9050979614257812,
      "learning_rate": 3.6666666666666666e-05,
      "loss": 2.6977,
      "step": 1200
    },
    {
      "epoch": 0.5333333333333333,
      "eval_loss": 2.7505874633789062,
      "eval_runtime": 197.7955,
      "eval_samples_per_second": 10.111,
      "eval_steps_per_second": 1.264,
      "step": 1200
    },
    {
      "epoch": 0.5377777777777778,
      "grad_norm": 0.917564332485199,
      "learning_rate": 3.655555555555556e-05,
      "loss": 2.7163,
      "step": 1210
    },
    {
      "epoch": 0.5422222222222223,
      "grad_norm": 0.9053695201873779,
      "learning_rate": 3.644444444444445e-05,
      "loss": 2.729,
      "step": 1220
    },
    {
      "epoch": 0.5466666666666666,
      "grad_norm": 0.8832120299339294,
      "learning_rate": 3.633333333333333e-05,
      "loss": 2.6669,
      "step": 1230
    },
    {
      "epoch": 0.5511111111111111,
      "grad_norm": 0.9926632642745972,
      "learning_rate": 3.6222222222222225e-05,
      "loss": 2.7616,
      "step": 1240
    },
    {
      "epoch": 0.5555555555555556,
      "grad_norm": 0.9428725242614746,
      "learning_rate": 3.611111111111111e-05,
      "loss": 2.7786,
      "step": 1250
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.7886406779289246,
      "learning_rate": 3.6e-05,
      "loss": 2.7401,
      "step": 1260
    },
    {
      "epoch": 0.5644444444444444,
      "grad_norm": 0.9100197553634644,
      "learning_rate": 3.5888888888888886e-05,
      "loss": 2.7327,
      "step": 1270
    },
    {
      "epoch": 0.5688888888888889,
      "grad_norm": 1.1486583948135376,
      "learning_rate": 3.577777777777778e-05,
      "loss": 2.7112,
      "step": 1280
    },
    {
      "epoch": 0.5733333333333334,
      "grad_norm": 0.8284552097320557,
      "learning_rate": 3.566666666666667e-05,
      "loss": 2.6546,
      "step": 1290
    },
    {
      "epoch": 0.5777777777777777,
      "grad_norm": 0.8100426197052002,
      "learning_rate": 3.555555555555556e-05,
      "loss": 2.7192,
      "step": 1300
    },
    {
      "epoch": 0.5777777777777777,
      "eval_loss": 2.7486636638641357,
      "eval_runtime": 197.377,
      "eval_samples_per_second": 10.133,
      "eval_steps_per_second": 1.267,
      "step": 1300
    },
    {
      "epoch": 0.5822222222222222,
      "grad_norm": 0.8982465863227844,
      "learning_rate": 3.5444444444444445e-05,
      "loss": 2.6709,
      "step": 1310
    },
    {
      "epoch": 0.5866666666666667,
      "grad_norm": 0.7135079503059387,
      "learning_rate": 3.5333333333333336e-05,
      "loss": 2.675,
      "step": 1320
    },
    {
      "epoch": 0.5911111111111111,
      "grad_norm": 0.8358967900276184,
      "learning_rate": 3.522222222222222e-05,
      "loss": 2.7026,
      "step": 1330
    },
    {
      "epoch": 0.5955555555555555,
      "grad_norm": 0.8933197259902954,
      "learning_rate": 3.511111111111111e-05,
      "loss": 2.7358,
      "step": 1340
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.823619544506073,
      "learning_rate": 3.5e-05,
      "loss": 2.771,
      "step": 1350
    },
    {
      "epoch": 0.6044444444444445,
      "grad_norm": 0.9139438271522522,
      "learning_rate": 3.4888888888888895e-05,
      "loss": 2.673,
      "step": 1360
    },
    {
      "epoch": 0.6088888888888889,
      "grad_norm": 0.8589253425598145,
      "learning_rate": 3.477777777777778e-05,
      "loss": 2.7071,
      "step": 1370
    },
    {
      "epoch": 0.6133333333333333,
      "grad_norm": 0.8001383543014526,
      "learning_rate": 3.466666666666667e-05,
      "loss": 2.792,
      "step": 1380
    },
    {
      "epoch": 0.6177777777777778,
      "grad_norm": 0.741032063961029,
      "learning_rate": 3.4555555555555556e-05,
      "loss": 2.7859,
      "step": 1390
    },
    {
      "epoch": 0.6222222222222222,
      "grad_norm": 0.7743961811065674,
      "learning_rate": 3.444444444444445e-05,
      "loss": 2.6682,
      "step": 1400
    },
    {
      "epoch": 0.6222222222222222,
      "eval_loss": 2.747687578201294,
      "eval_runtime": 199.0246,
      "eval_samples_per_second": 10.049,
      "eval_steps_per_second": 1.256,
      "step": 1400
    },
    {
      "epoch": 0.6266666666666667,
      "grad_norm": 0.7884698510169983,
      "learning_rate": 3.433333333333333e-05,
      "loss": 2.6769,
      "step": 1410
    },
    {
      "epoch": 0.6311111111111111,
      "grad_norm": 0.69902104139328,
      "learning_rate": 3.4222222222222224e-05,
      "loss": 2.7717,
      "step": 1420
    },
    {
      "epoch": 0.6355555555555555,
      "grad_norm": 0.8855377435684204,
      "learning_rate": 3.411111111111111e-05,
      "loss": 2.6489,
      "step": 1430
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.7787487506866455,
      "learning_rate": 3.4000000000000007e-05,
      "loss": 2.743,
      "step": 1440
    },
    {
      "epoch": 0.6444444444444445,
      "grad_norm": 0.7790982723236084,
      "learning_rate": 3.388888888888889e-05,
      "loss": 2.805,
      "step": 1450
    },
    {
      "epoch": 0.6488888888888888,
      "grad_norm": 0.8405389189720154,
      "learning_rate": 3.377777777777778e-05,
      "loss": 2.7428,
      "step": 1460
    },
    {
      "epoch": 0.6533333333333333,
      "grad_norm": 0.7092770338058472,
      "learning_rate": 3.366666666666667e-05,
      "loss": 2.7617,
      "step": 1470
    },
    {
      "epoch": 0.6577777777777778,
      "grad_norm": 1.0032601356506348,
      "learning_rate": 3.355555555555556e-05,
      "loss": 2.7679,
      "step": 1480
    },
    {
      "epoch": 0.6622222222222223,
      "grad_norm": 0.7225045561790466,
      "learning_rate": 3.3444444444444443e-05,
      "loss": 2.6645,
      "step": 1490
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 0.7815588712692261,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 2.796,
      "step": 1500
    },
    {
      "epoch": 0.6666666666666666,
      "eval_loss": 2.744640588760376,
      "eval_runtime": 197.3554,
      "eval_samples_per_second": 10.134,
      "eval_steps_per_second": 1.267,
      "step": 1500
    },
    {
      "epoch": 0.6711111111111111,
      "grad_norm": 0.9587300419807434,
      "learning_rate": 3.322222222222222e-05,
      "loss": 2.6817,
      "step": 1510
    },
    {
      "epoch": 0.6755555555555556,
      "grad_norm": 0.9502821564674377,
      "learning_rate": 3.311111111111112e-05,
      "loss": 2.7515,
      "step": 1520
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.9076757431030273,
      "learning_rate": 3.3e-05,
      "loss": 2.7005,
      "step": 1530
    },
    {
      "epoch": 0.6844444444444444,
      "grad_norm": 0.9301269054412842,
      "learning_rate": 3.2888888888888894e-05,
      "loss": 2.8605,
      "step": 1540
    },
    {
      "epoch": 0.6888888888888889,
      "grad_norm": 0.8195439577102661,
      "learning_rate": 3.277777777777778e-05,
      "loss": 2.6908,
      "step": 1550
    },
    {
      "epoch": 0.6933333333333334,
      "grad_norm": 0.7542176842689514,
      "learning_rate": 3.266666666666667e-05,
      "loss": 2.7567,
      "step": 1560
    },
    {
      "epoch": 0.6977777777777778,
      "grad_norm": 0.9190207719802856,
      "learning_rate": 3.2555555555555555e-05,
      "loss": 2.6674,
      "step": 1570
    },
    {
      "epoch": 0.7022222222222222,
      "grad_norm": 1.1770470142364502,
      "learning_rate": 3.2444444444444446e-05,
      "loss": 2.686,
      "step": 1580
    },
    {
      "epoch": 0.7066666666666667,
      "grad_norm": 0.6972286105155945,
      "learning_rate": 3.233333333333333e-05,
      "loss": 2.6882,
      "step": 1590
    },
    {
      "epoch": 0.7111111111111111,
      "grad_norm": 0.864646852016449,
      "learning_rate": 3.222222222222223e-05,
      "loss": 2.5892,
      "step": 1600
    },
    {
      "epoch": 0.7111111111111111,
      "eval_loss": 2.7439045906066895,
      "eval_runtime": 197.5108,
      "eval_samples_per_second": 10.126,
      "eval_steps_per_second": 1.266,
      "step": 1600
    },
    {
      "epoch": 0.7155555555555555,
      "grad_norm": 0.8685358166694641,
      "learning_rate": 3.2111111111111114e-05,
      "loss": 2.681,
      "step": 1610
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.7742667198181152,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 2.7378,
      "step": 1620
    },
    {
      "epoch": 0.7244444444444444,
      "grad_norm": 0.7423231601715088,
      "learning_rate": 3.188888888888889e-05,
      "loss": 2.7419,
      "step": 1630
    },
    {
      "epoch": 0.7288888888888889,
      "grad_norm": 0.8788865208625793,
      "learning_rate": 3.177777777777778e-05,
      "loss": 2.7587,
      "step": 1640
    },
    {
      "epoch": 0.7333333333333333,
      "grad_norm": 0.9843416810035706,
      "learning_rate": 3.1666666666666666e-05,
      "loss": 2.9244,
      "step": 1650
    },
    {
      "epoch": 0.7377777777777778,
      "grad_norm": 0.7743030786514282,
      "learning_rate": 3.155555555555556e-05,
      "loss": 2.8052,
      "step": 1660
    },
    {
      "epoch": 0.7422222222222222,
      "grad_norm": 0.8351013660430908,
      "learning_rate": 3.144444444444445e-05,
      "loss": 2.67,
      "step": 1670
    },
    {
      "epoch": 0.7466666666666667,
      "grad_norm": 0.8786852359771729,
      "learning_rate": 3.1333333333333334e-05,
      "loss": 2.7831,
      "step": 1680
    },
    {
      "epoch": 0.7511111111111111,
      "grad_norm": 0.8547019362449646,
      "learning_rate": 3.1222222222222225e-05,
      "loss": 2.7053,
      "step": 1690
    },
    {
      "epoch": 0.7555555555555555,
      "grad_norm": 0.7061131596565247,
      "learning_rate": 3.111111111111111e-05,
      "loss": 2.7585,
      "step": 1700
    },
    {
      "epoch": 0.7555555555555555,
      "eval_loss": 2.741579532623291,
      "eval_runtime": 197.5578,
      "eval_samples_per_second": 10.124,
      "eval_steps_per_second": 1.265,
      "step": 1700
    }
  ],
  "logging_steps": 10,
  "max_steps": 4500,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3.3679997927424e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
