{
  "best_metric": 2.722587823867798,
  "best_model_checkpoint": "./outputs/checkpoint-4000",
  "epoch": 1.7777777777777777,
  "eval_steps": 100,
  "global_step": 4000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0044444444444444444,
      "grad_norm": 0.6385458707809448,
      "learning_rate": 4.9888888888888894e-05,
      "loss": 3.4474,
      "step": 10
    },
    {
      "epoch": 0.008888888888888889,
      "grad_norm": 0.5836634635925293,
      "learning_rate": 4.977777777777778e-05,
      "loss": 3.2499,
      "step": 20
    },
    {
      "epoch": 0.013333333333333334,
      "grad_norm": 0.5975626111030579,
      "learning_rate": 4.966666666666667e-05,
      "loss": 2.9499,
      "step": 30
    },
    {
      "epoch": 0.017777777777777778,
      "grad_norm": 0.5284260511398315,
      "learning_rate": 4.955555555555556e-05,
      "loss": 2.9841,
      "step": 40
    },
    {
      "epoch": 0.022222222222222223,
      "grad_norm": 0.4768317639827728,
      "learning_rate": 4.9444444444444446e-05,
      "loss": 2.8488,
      "step": 50
    },
    {
      "epoch": 0.02666666666666667,
      "grad_norm": 0.6019676923751831,
      "learning_rate": 4.933333333333334e-05,
      "loss": 2.8174,
      "step": 60
    },
    {
      "epoch": 0.03111111111111111,
      "grad_norm": 0.4315429627895355,
      "learning_rate": 4.922222222222222e-05,
      "loss": 2.8301,
      "step": 70
    },
    {
      "epoch": 0.035555555555555556,
      "grad_norm": 0.5725593566894531,
      "learning_rate": 4.9111111111111114e-05,
      "loss": 2.8291,
      "step": 80
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.5543215274810791,
      "learning_rate": 4.9e-05,
      "loss": 2.8156,
      "step": 90
    },
    {
      "epoch": 0.044444444444444446,
      "grad_norm": 0.4583193063735962,
      "learning_rate": 4.888888888888889e-05,
      "loss": 2.8502,
      "step": 100
    },
    {
      "epoch": 0.044444444444444446,
      "eval_loss": 2.8353183269500732,
      "eval_runtime": 197.5325,
      "eval_samples_per_second": 10.125,
      "eval_steps_per_second": 1.266,
      "step": 100
    },
    {
      "epoch": 0.04888888888888889,
      "grad_norm": 0.6037725210189819,
      "learning_rate": 4.8777777777777775e-05,
      "loss": 2.8819,
      "step": 110
    },
    {
      "epoch": 0.05333333333333334,
      "grad_norm": 0.6795234084129333,
      "learning_rate": 4.866666666666667e-05,
      "loss": 2.9167,
      "step": 120
    },
    {
      "epoch": 0.057777777777777775,
      "grad_norm": 0.674334704875946,
      "learning_rate": 4.855555555555556e-05,
      "loss": 2.7826,
      "step": 130
    },
    {
      "epoch": 0.06222222222222222,
      "grad_norm": 0.6613140106201172,
      "learning_rate": 4.844444444444445e-05,
      "loss": 2.8455,
      "step": 140
    },
    {
      "epoch": 0.06666666666666667,
      "grad_norm": 0.7885493040084839,
      "learning_rate": 4.8333333333333334e-05,
      "loss": 2.7365,
      "step": 150
    },
    {
      "epoch": 0.07111111111111111,
      "grad_norm": 0.8391779661178589,
      "learning_rate": 4.8222222222222225e-05,
      "loss": 2.7638,
      "step": 160
    },
    {
      "epoch": 0.07555555555555556,
      "grad_norm": 0.6468204855918884,
      "learning_rate": 4.811111111111111e-05,
      "loss": 2.7456,
      "step": 170
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.683377742767334,
      "learning_rate": 4.8e-05,
      "loss": 2.801,
      "step": 180
    },
    {
      "epoch": 0.08444444444444445,
      "grad_norm": 0.5992774963378906,
      "learning_rate": 4.7888888888888886e-05,
      "loss": 2.7839,
      "step": 190
    },
    {
      "epoch": 0.08888888888888889,
      "grad_norm": 0.6587018966674805,
      "learning_rate": 4.7777777777777784e-05,
      "loss": 2.8475,
      "step": 200
    },
    {
      "epoch": 0.08888888888888889,
      "eval_loss": 2.8036391735076904,
      "eval_runtime": 197.5629,
      "eval_samples_per_second": 10.123,
      "eval_steps_per_second": 1.265,
      "step": 200
    },
    {
      "epoch": 0.09333333333333334,
      "grad_norm": 0.6106796860694885,
      "learning_rate": 4.766666666666667e-05,
      "loss": 2.702,
      "step": 210
    },
    {
      "epoch": 0.09777777777777778,
      "grad_norm": 1.0709853172302246,
      "learning_rate": 4.755555555555556e-05,
      "loss": 2.6563,
      "step": 220
    },
    {
      "epoch": 0.10222222222222223,
      "grad_norm": 0.766156792640686,
      "learning_rate": 4.7444444444444445e-05,
      "loss": 2.7211,
      "step": 230
    },
    {
      "epoch": 0.10666666666666667,
      "grad_norm": 0.7021797895431519,
      "learning_rate": 4.7333333333333336e-05,
      "loss": 2.7997,
      "step": 240
    },
    {
      "epoch": 0.1111111111111111,
      "grad_norm": 0.7881563305854797,
      "learning_rate": 4.722222222222222e-05,
      "loss": 2.7492,
      "step": 250
    },
    {
      "epoch": 0.11555555555555555,
      "grad_norm": 0.7008208632469177,
      "learning_rate": 4.711111111111111e-05,
      "loss": 2.7347,
      "step": 260
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5889718532562256,
      "learning_rate": 4.7e-05,
      "loss": 2.7529,
      "step": 270
    },
    {
      "epoch": 0.12444444444444444,
      "grad_norm": 0.7305594682693481,
      "learning_rate": 4.6888888888888895e-05,
      "loss": 2.7243,
      "step": 280
    },
    {
      "epoch": 0.1288888888888889,
      "grad_norm": 0.7315137386322021,
      "learning_rate": 4.677777777777778e-05,
      "loss": 2.7451,
      "step": 290
    },
    {
      "epoch": 0.13333333333333333,
      "grad_norm": 0.7913298606872559,
      "learning_rate": 4.666666666666667e-05,
      "loss": 2.7776,
      "step": 300
    },
    {
      "epoch": 0.13333333333333333,
      "eval_loss": 2.788290500640869,
      "eval_runtime": 197.4899,
      "eval_samples_per_second": 10.127,
      "eval_steps_per_second": 1.266,
      "step": 300
    },
    {
      "epoch": 0.13777777777777778,
      "grad_norm": 0.672248125076294,
      "learning_rate": 4.6555555555555556e-05,
      "loss": 2.8238,
      "step": 310
    },
    {
      "epoch": 0.14222222222222222,
      "grad_norm": 0.6893551349639893,
      "learning_rate": 4.644444444444445e-05,
      "loss": 2.7119,
      "step": 320
    },
    {
      "epoch": 0.14666666666666667,
      "grad_norm": 0.7400459051132202,
      "learning_rate": 4.633333333333333e-05,
      "loss": 2.7798,
      "step": 330
    },
    {
      "epoch": 0.1511111111111111,
      "grad_norm": 1.0300168991088867,
      "learning_rate": 4.6222222222222224e-05,
      "loss": 2.7234,
      "step": 340
    },
    {
      "epoch": 0.15555555555555556,
      "grad_norm": 0.622245192527771,
      "learning_rate": 4.6111111111111115e-05,
      "loss": 2.7447,
      "step": 350
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.749061644077301,
      "learning_rate": 4.600000000000001e-05,
      "loss": 2.7392,
      "step": 360
    },
    {
      "epoch": 0.16444444444444445,
      "grad_norm": 1.0893040895462036,
      "learning_rate": 4.588888888888889e-05,
      "loss": 2.871,
      "step": 370
    },
    {
      "epoch": 0.1688888888888889,
      "grad_norm": 0.7031847834587097,
      "learning_rate": 4.577777777777778e-05,
      "loss": 2.7384,
      "step": 380
    },
    {
      "epoch": 0.17333333333333334,
      "grad_norm": 0.9796207547187805,
      "learning_rate": 4.566666666666667e-05,
      "loss": 2.7469,
      "step": 390
    },
    {
      "epoch": 0.17777777777777778,
      "grad_norm": 1.1894820928573608,
      "learning_rate": 4.555555555555556e-05,
      "loss": 2.7717,
      "step": 400
    },
    {
      "epoch": 0.17777777777777778,
      "eval_loss": 2.782315254211426,
      "eval_runtime": 197.5715,
      "eval_samples_per_second": 10.123,
      "eval_steps_per_second": 1.265,
      "step": 400
    },
    {
      "epoch": 0.18222222222222223,
      "grad_norm": 0.9657090902328491,
      "learning_rate": 4.5444444444444444e-05,
      "loss": 2.7223,
      "step": 410
    },
    {
      "epoch": 0.18666666666666668,
      "grad_norm": 0.9215372204780579,
      "learning_rate": 4.5333333333333335e-05,
      "loss": 2.801,
      "step": 420
    },
    {
      "epoch": 0.19111111111111112,
      "grad_norm": 0.8388105034828186,
      "learning_rate": 4.522222222222223e-05,
      "loss": 2.7478,
      "step": 430
    },
    {
      "epoch": 0.19555555555555557,
      "grad_norm": 0.8535682559013367,
      "learning_rate": 4.511111111111112e-05,
      "loss": 2.6471,
      "step": 440
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.9995908141136169,
      "learning_rate": 4.5e-05,
      "loss": 2.6696,
      "step": 450
    },
    {
      "epoch": 0.20444444444444446,
      "grad_norm": 0.701619029045105,
      "learning_rate": 4.4888888888888894e-05,
      "loss": 2.6829,
      "step": 460
    },
    {
      "epoch": 0.2088888888888889,
      "grad_norm": 0.7900257706642151,
      "learning_rate": 4.477777777777778e-05,
      "loss": 2.7647,
      "step": 470
    },
    {
      "epoch": 0.21333333333333335,
      "grad_norm": 0.7405385375022888,
      "learning_rate": 4.466666666666667e-05,
      "loss": 2.7003,
      "step": 480
    },
    {
      "epoch": 0.21777777777777776,
      "grad_norm": 0.7802812457084656,
      "learning_rate": 4.4555555555555555e-05,
      "loss": 2.7491,
      "step": 490
    },
    {
      "epoch": 0.2222222222222222,
      "grad_norm": 0.7782845497131348,
      "learning_rate": 4.4444444444444447e-05,
      "loss": 2.8225,
      "step": 500
    },
    {
      "epoch": 0.2222222222222222,
      "eval_loss": 2.7725062370300293,
      "eval_runtime": 197.2198,
      "eval_samples_per_second": 10.141,
      "eval_steps_per_second": 1.268,
      "step": 500
    },
    {
      "epoch": 0.22666666666666666,
      "grad_norm": 0.6806333661079407,
      "learning_rate": 4.433333333333334e-05,
      "loss": 2.7608,
      "step": 510
    },
    {
      "epoch": 0.2311111111111111,
      "grad_norm": 0.6650264263153076,
      "learning_rate": 4.422222222222222e-05,
      "loss": 2.8454,
      "step": 520
    },
    {
      "epoch": 0.23555555555555555,
      "grad_norm": 0.647793710231781,
      "learning_rate": 4.4111111111111114e-05,
      "loss": 2.8493,
      "step": 530
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.7477841377258301,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 2.6885,
      "step": 540
    },
    {
      "epoch": 0.24444444444444444,
      "grad_norm": 0.6355180740356445,
      "learning_rate": 4.388888888888889e-05,
      "loss": 2.7658,
      "step": 550
    },
    {
      "epoch": 0.24888888888888888,
      "grad_norm": 0.743603527545929,
      "learning_rate": 4.377777777777778e-05,
      "loss": 2.7571,
      "step": 560
    },
    {
      "epoch": 0.25333333333333335,
      "grad_norm": 0.7004106044769287,
      "learning_rate": 4.3666666666666666e-05,
      "loss": 2.73,
      "step": 570
    },
    {
      "epoch": 0.2577777777777778,
      "grad_norm": 0.8036758303642273,
      "learning_rate": 4.355555555555556e-05,
      "loss": 2.7492,
      "step": 580
    },
    {
      "epoch": 0.26222222222222225,
      "grad_norm": 0.9417545199394226,
      "learning_rate": 4.344444444444445e-05,
      "loss": 2.726,
      "step": 590
    },
    {
      "epoch": 0.26666666666666666,
      "grad_norm": 0.8402337431907654,
      "learning_rate": 4.3333333333333334e-05,
      "loss": 2.674,
      "step": 600
    },
    {
      "epoch": 0.26666666666666666,
      "eval_loss": 2.7687604427337646,
      "eval_runtime": 197.1542,
      "eval_samples_per_second": 10.144,
      "eval_steps_per_second": 1.268,
      "step": 600
    },
    {
      "epoch": 0.27111111111111114,
      "grad_norm": 0.7417306900024414,
      "learning_rate": 4.3222222222222226e-05,
      "loss": 2.7678,
      "step": 610
    },
    {
      "epoch": 0.27555555555555555,
      "grad_norm": 1.0891952514648438,
      "learning_rate": 4.311111111111111e-05,
      "loss": 2.7515,
      "step": 620
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.6318672895431519,
      "learning_rate": 4.3e-05,
      "loss": 2.8414,
      "step": 630
    },
    {
      "epoch": 0.28444444444444444,
      "grad_norm": 0.9144419431686401,
      "learning_rate": 4.2888888888888886e-05,
      "loss": 2.6959,
      "step": 640
    },
    {
      "epoch": 0.28888888888888886,
      "grad_norm": 0.7177309989929199,
      "learning_rate": 4.277777777777778e-05,
      "loss": 2.7571,
      "step": 650
    },
    {
      "epoch": 0.29333333333333333,
      "grad_norm": 0.788387656211853,
      "learning_rate": 4.266666666666667e-05,
      "loss": 2.7638,
      "step": 660
    },
    {
      "epoch": 0.29777777777777775,
      "grad_norm": 0.8486708998680115,
      "learning_rate": 4.255555555555556e-05,
      "loss": 2.6516,
      "step": 670
    },
    {
      "epoch": 0.3022222222222222,
      "grad_norm": 0.7327678799629211,
      "learning_rate": 4.2444444444444445e-05,
      "loss": 2.7269,
      "step": 680
    },
    {
      "epoch": 0.30666666666666664,
      "grad_norm": 0.8359125852584839,
      "learning_rate": 4.233333333333334e-05,
      "loss": 2.8246,
      "step": 690
    },
    {
      "epoch": 0.3111111111111111,
      "grad_norm": 0.7560226917266846,
      "learning_rate": 4.222222222222222e-05,
      "loss": 2.7814,
      "step": 700
    },
    {
      "epoch": 0.3111111111111111,
      "eval_loss": 2.7650961875915527,
      "eval_runtime": 198.6402,
      "eval_samples_per_second": 10.068,
      "eval_steps_per_second": 1.259,
      "step": 700
    },
    {
      "epoch": 0.31555555555555553,
      "grad_norm": 1.067901849746704,
      "learning_rate": 4.211111111111111e-05,
      "loss": 2.7116,
      "step": 710
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.9432044625282288,
      "learning_rate": 4.2e-05,
      "loss": 2.6898,
      "step": 720
    },
    {
      "epoch": 0.3244444444444444,
      "grad_norm": 0.8957403302192688,
      "learning_rate": 4.188888888888889e-05,
      "loss": 2.7443,
      "step": 730
    },
    {
      "epoch": 0.3288888888888889,
      "grad_norm": 0.6469542980194092,
      "learning_rate": 4.177777777777778e-05,
      "loss": 2.6894,
      "step": 740
    },
    {
      "epoch": 0.3333333333333333,
      "grad_norm": 0.8531420826911926,
      "learning_rate": 4.166666666666667e-05,
      "loss": 2.7056,
      "step": 750
    },
    {
      "epoch": 0.3377777777777778,
      "grad_norm": 0.8999106287956238,
      "learning_rate": 4.155555555555556e-05,
      "loss": 2.6939,
      "step": 760
    },
    {
      "epoch": 0.3422222222222222,
      "grad_norm": 0.7439743876457214,
      "learning_rate": 4.144444444444445e-05,
      "loss": 2.7058,
      "step": 770
    },
    {
      "epoch": 0.3466666666666667,
      "grad_norm": 0.8376057147979736,
      "learning_rate": 4.133333333333333e-05,
      "loss": 2.8228,
      "step": 780
    },
    {
      "epoch": 0.3511111111111111,
      "grad_norm": 0.8972124457359314,
      "learning_rate": 4.1222222222222224e-05,
      "loss": 2.8116,
      "step": 790
    },
    {
      "epoch": 0.35555555555555557,
      "grad_norm": 0.8277852535247803,
      "learning_rate": 4.111111111111111e-05,
      "loss": 2.6769,
      "step": 800
    },
    {
      "epoch": 0.35555555555555557,
      "eval_loss": 2.7616944313049316,
      "eval_runtime": 198.6423,
      "eval_samples_per_second": 10.068,
      "eval_steps_per_second": 1.259,
      "step": 800
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.7409864664077759,
      "learning_rate": 4.1e-05,
      "loss": 2.7243,
      "step": 810
    },
    {
      "epoch": 0.36444444444444446,
      "grad_norm": 0.7423574924468994,
      "learning_rate": 4.088888888888889e-05,
      "loss": 2.8037,
      "step": 820
    },
    {
      "epoch": 0.3688888888888889,
      "grad_norm": 0.8455179333686829,
      "learning_rate": 4.0777777777777783e-05,
      "loss": 2.9172,
      "step": 830
    },
    {
      "epoch": 0.37333333333333335,
      "grad_norm": 0.7147595286369324,
      "learning_rate": 4.066666666666667e-05,
      "loss": 2.7305,
      "step": 840
    },
    {
      "epoch": 0.37777777777777777,
      "grad_norm": 1.0532411336898804,
      "learning_rate": 4.055555555555556e-05,
      "loss": 2.7317,
      "step": 850
    },
    {
      "epoch": 0.38222222222222224,
      "grad_norm": 4.514044284820557,
      "learning_rate": 4.0444444444444444e-05,
      "loss": 2.8281,
      "step": 860
    },
    {
      "epoch": 0.38666666666666666,
      "grad_norm": 0.7768872976303101,
      "learning_rate": 4.0333333333333336e-05,
      "loss": 2.8237,
      "step": 870
    },
    {
      "epoch": 0.39111111111111113,
      "grad_norm": 0.7565159797668457,
      "learning_rate": 4.022222222222222e-05,
      "loss": 2.7731,
      "step": 880
    },
    {
      "epoch": 0.39555555555555555,
      "grad_norm": 0.8025693893432617,
      "learning_rate": 4.011111111111111e-05,
      "loss": 2.6645,
      "step": 890
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.6811626553535461,
      "learning_rate": 4e-05,
      "loss": 2.7047,
      "step": 900
    },
    {
      "epoch": 0.4,
      "eval_loss": 2.7587039470672607,
      "eval_runtime": 196.7503,
      "eval_samples_per_second": 10.165,
      "eval_steps_per_second": 1.271,
      "step": 900
    },
    {
      "epoch": 0.40444444444444444,
      "grad_norm": 0.9500214457511902,
      "learning_rate": 3.9888888888888895e-05,
      "loss": 2.8124,
      "step": 910
    },
    {
      "epoch": 0.4088888888888889,
      "grad_norm": 0.7919833064079285,
      "learning_rate": 3.977777777777778e-05,
      "loss": 2.7481,
      "step": 920
    },
    {
      "epoch": 0.41333333333333333,
      "grad_norm": 0.8032611608505249,
      "learning_rate": 3.966666666666667e-05,
      "loss": 2.816,
      "step": 930
    },
    {
      "epoch": 0.4177777777777778,
      "grad_norm": 1.011407494544983,
      "learning_rate": 3.9555555555555556e-05,
      "loss": 2.6621,
      "step": 940
    },
    {
      "epoch": 0.4222222222222222,
      "grad_norm": 0.9008998870849609,
      "learning_rate": 3.944444444444445e-05,
      "loss": 2.74,
      "step": 950
    },
    {
      "epoch": 0.4266666666666667,
      "grad_norm": 1.185471534729004,
      "learning_rate": 3.933333333333333e-05,
      "loss": 2.6981,
      "step": 960
    },
    {
      "epoch": 0.4311111111111111,
      "grad_norm": 1.201636552810669,
      "learning_rate": 3.922222222222223e-05,
      "loss": 2.7555,
      "step": 970
    },
    {
      "epoch": 0.43555555555555553,
      "grad_norm": 0.8024631142616272,
      "learning_rate": 3.9111111111111115e-05,
      "loss": 2.7641,
      "step": 980
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6904645562171936,
      "learning_rate": 3.9000000000000006e-05,
      "loss": 2.6611,
      "step": 990
    },
    {
      "epoch": 0.4444444444444444,
      "grad_norm": 0.7890646457672119,
      "learning_rate": 3.888888888888889e-05,
      "loss": 2.7008,
      "step": 1000
    },
    {
      "epoch": 0.4444444444444444,
      "eval_loss": 2.756218194961548,
      "eval_runtime": 197.5331,
      "eval_samples_per_second": 10.125,
      "eval_steps_per_second": 1.266,
      "step": 1000
    },
    {
      "epoch": 0.4488888888888889,
      "grad_norm": 0.890580952167511,
      "learning_rate": 3.877777777777778e-05,
      "loss": 2.7164,
      "step": 1010
    },
    {
      "epoch": 0.4533333333333333,
      "grad_norm": 0.8256881833076477,
      "learning_rate": 3.866666666666667e-05,
      "loss": 2.7487,
      "step": 1020
    },
    {
      "epoch": 0.4577777777777778,
      "grad_norm": 0.8078989386558533,
      "learning_rate": 3.855555555555556e-05,
      "loss": 2.7375,
      "step": 1030
    },
    {
      "epoch": 0.4622222222222222,
      "grad_norm": 0.8892345428466797,
      "learning_rate": 3.844444444444444e-05,
      "loss": 2.6949,
      "step": 1040
    },
    {
      "epoch": 0.4666666666666667,
      "grad_norm": 0.8739168643951416,
      "learning_rate": 3.8333333333333334e-05,
      "loss": 2.751,
      "step": 1050
    },
    {
      "epoch": 0.4711111111111111,
      "grad_norm": 0.8137445449829102,
      "learning_rate": 3.8222222222222226e-05,
      "loss": 2.7603,
      "step": 1060
    },
    {
      "epoch": 0.47555555555555556,
      "grad_norm": 1.027011513710022,
      "learning_rate": 3.811111111111112e-05,
      "loss": 2.7133,
      "step": 1070
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.7454120516777039,
      "learning_rate": 3.8e-05,
      "loss": 2.7783,
      "step": 1080
    },
    {
      "epoch": 0.48444444444444446,
      "grad_norm": 0.7455510497093201,
      "learning_rate": 3.7888888888888894e-05,
      "loss": 2.6809,
      "step": 1090
    },
    {
      "epoch": 0.4888888888888889,
      "grad_norm": 0.9306420087814331,
      "learning_rate": 3.777777777777778e-05,
      "loss": 2.6699,
      "step": 1100
    },
    {
      "epoch": 0.4888888888888889,
      "eval_loss": 2.754688024520874,
      "eval_runtime": 197.4911,
      "eval_samples_per_second": 10.127,
      "eval_steps_per_second": 1.266,
      "step": 1100
    },
    {
      "epoch": 0.49333333333333335,
      "grad_norm": 0.7359369397163391,
      "learning_rate": 3.766666666666667e-05,
      "loss": 2.6942,
      "step": 1110
    },
    {
      "epoch": 0.49777777777777776,
      "grad_norm": 0.7743101716041565,
      "learning_rate": 3.7555555555555554e-05,
      "loss": 2.7639,
      "step": 1120
    },
    {
      "epoch": 0.5022222222222222,
      "grad_norm": 0.8032435774803162,
      "learning_rate": 3.7444444444444446e-05,
      "loss": 2.7723,
      "step": 1130
    },
    {
      "epoch": 0.5066666666666667,
      "grad_norm": 0.9717305898666382,
      "learning_rate": 3.733333333333334e-05,
      "loss": 2.6971,
      "step": 1140
    },
    {
      "epoch": 0.5111111111111111,
      "grad_norm": 0.9070069193840027,
      "learning_rate": 3.722222222222222e-05,
      "loss": 2.7381,
      "step": 1150
    },
    {
      "epoch": 0.5155555555555555,
      "grad_norm": 0.9354702234268188,
      "learning_rate": 3.7111111111111113e-05,
      "loss": 2.7848,
      "step": 1160
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.8274703621864319,
      "learning_rate": 3.7e-05,
      "loss": 2.6586,
      "step": 1170
    },
    {
      "epoch": 0.5244444444444445,
      "grad_norm": 0.6774625778198242,
      "learning_rate": 3.688888888888889e-05,
      "loss": 2.7436,
      "step": 1180
    },
    {
      "epoch": 0.5288888888888889,
      "grad_norm": 0.8063578605651855,
      "learning_rate": 3.677777777777778e-05,
      "loss": 2.7168,
      "step": 1190
    },
    {
      "epoch": 0.5333333333333333,
      "grad_norm": 0.9050979614257812,
      "learning_rate": 3.6666666666666666e-05,
      "loss": 2.6977,
      "step": 1200
    },
    {
      "epoch": 0.5333333333333333,
      "eval_loss": 2.7505874633789062,
      "eval_runtime": 197.7955,
      "eval_samples_per_second": 10.111,
      "eval_steps_per_second": 1.264,
      "step": 1200
    },
    {
      "epoch": 0.5377777777777778,
      "grad_norm": 0.917564332485199,
      "learning_rate": 3.655555555555556e-05,
      "loss": 2.7163,
      "step": 1210
    },
    {
      "epoch": 0.5422222222222223,
      "grad_norm": 0.9053695201873779,
      "learning_rate": 3.644444444444445e-05,
      "loss": 2.729,
      "step": 1220
    },
    {
      "epoch": 0.5466666666666666,
      "grad_norm": 0.8832120299339294,
      "learning_rate": 3.633333333333333e-05,
      "loss": 2.6669,
      "step": 1230
    },
    {
      "epoch": 0.5511111111111111,
      "grad_norm": 0.9926632642745972,
      "learning_rate": 3.6222222222222225e-05,
      "loss": 2.7616,
      "step": 1240
    },
    {
      "epoch": 0.5555555555555556,
      "grad_norm": 0.9428725242614746,
      "learning_rate": 3.611111111111111e-05,
      "loss": 2.7786,
      "step": 1250
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.7886406779289246,
      "learning_rate": 3.6e-05,
      "loss": 2.7401,
      "step": 1260
    },
    {
      "epoch": 0.5644444444444444,
      "grad_norm": 0.9100197553634644,
      "learning_rate": 3.5888888888888886e-05,
      "loss": 2.7327,
      "step": 1270
    },
    {
      "epoch": 0.5688888888888889,
      "grad_norm": 1.1486583948135376,
      "learning_rate": 3.577777777777778e-05,
      "loss": 2.7112,
      "step": 1280
    },
    {
      "epoch": 0.5733333333333334,
      "grad_norm": 0.8284552097320557,
      "learning_rate": 3.566666666666667e-05,
      "loss": 2.6546,
      "step": 1290
    },
    {
      "epoch": 0.5777777777777777,
      "grad_norm": 0.8100426197052002,
      "learning_rate": 3.555555555555556e-05,
      "loss": 2.7192,
      "step": 1300
    },
    {
      "epoch": 0.5777777777777777,
      "eval_loss": 2.7486636638641357,
      "eval_runtime": 197.377,
      "eval_samples_per_second": 10.133,
      "eval_steps_per_second": 1.267,
      "step": 1300
    },
    {
      "epoch": 0.5822222222222222,
      "grad_norm": 0.8982465863227844,
      "learning_rate": 3.5444444444444445e-05,
      "loss": 2.6709,
      "step": 1310
    },
    {
      "epoch": 0.5866666666666667,
      "grad_norm": 0.7135079503059387,
      "learning_rate": 3.5333333333333336e-05,
      "loss": 2.675,
      "step": 1320
    },
    {
      "epoch": 0.5911111111111111,
      "grad_norm": 0.8358967900276184,
      "learning_rate": 3.522222222222222e-05,
      "loss": 2.7026,
      "step": 1330
    },
    {
      "epoch": 0.5955555555555555,
      "grad_norm": 0.8933197259902954,
      "learning_rate": 3.511111111111111e-05,
      "loss": 2.7358,
      "step": 1340
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.823619544506073,
      "learning_rate": 3.5e-05,
      "loss": 2.771,
      "step": 1350
    },
    {
      "epoch": 0.6044444444444445,
      "grad_norm": 0.9139438271522522,
      "learning_rate": 3.4888888888888895e-05,
      "loss": 2.673,
      "step": 1360
    },
    {
      "epoch": 0.6088888888888889,
      "grad_norm": 0.8589253425598145,
      "learning_rate": 3.477777777777778e-05,
      "loss": 2.7071,
      "step": 1370
    },
    {
      "epoch": 0.6133333333333333,
      "grad_norm": 0.8001383543014526,
      "learning_rate": 3.466666666666667e-05,
      "loss": 2.792,
      "step": 1380
    },
    {
      "epoch": 0.6177777777777778,
      "grad_norm": 0.741032063961029,
      "learning_rate": 3.4555555555555556e-05,
      "loss": 2.7859,
      "step": 1390
    },
    {
      "epoch": 0.6222222222222222,
      "grad_norm": 0.7743961811065674,
      "learning_rate": 3.444444444444445e-05,
      "loss": 2.6682,
      "step": 1400
    },
    {
      "epoch": 0.6222222222222222,
      "eval_loss": 2.747687578201294,
      "eval_runtime": 199.0246,
      "eval_samples_per_second": 10.049,
      "eval_steps_per_second": 1.256,
      "step": 1400
    },
    {
      "epoch": 0.6266666666666667,
      "grad_norm": 0.7884698510169983,
      "learning_rate": 3.433333333333333e-05,
      "loss": 2.6769,
      "step": 1410
    },
    {
      "epoch": 0.6311111111111111,
      "grad_norm": 0.69902104139328,
      "learning_rate": 3.4222222222222224e-05,
      "loss": 2.7717,
      "step": 1420
    },
    {
      "epoch": 0.6355555555555555,
      "grad_norm": 0.8855377435684204,
      "learning_rate": 3.411111111111111e-05,
      "loss": 2.6489,
      "step": 1430
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.7787487506866455,
      "learning_rate": 3.4000000000000007e-05,
      "loss": 2.743,
      "step": 1440
    },
    {
      "epoch": 0.6444444444444445,
      "grad_norm": 0.7790982723236084,
      "learning_rate": 3.388888888888889e-05,
      "loss": 2.805,
      "step": 1450
    },
    {
      "epoch": 0.6488888888888888,
      "grad_norm": 0.8405389189720154,
      "learning_rate": 3.377777777777778e-05,
      "loss": 2.7428,
      "step": 1460
    },
    {
      "epoch": 0.6533333333333333,
      "grad_norm": 0.7092770338058472,
      "learning_rate": 3.366666666666667e-05,
      "loss": 2.7617,
      "step": 1470
    },
    {
      "epoch": 0.6577777777777778,
      "grad_norm": 1.0032601356506348,
      "learning_rate": 3.355555555555556e-05,
      "loss": 2.7679,
      "step": 1480
    },
    {
      "epoch": 0.6622222222222223,
      "grad_norm": 0.7225045561790466,
      "learning_rate": 3.3444444444444443e-05,
      "loss": 2.6645,
      "step": 1490
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 0.7815588712692261,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 2.796,
      "step": 1500
    },
    {
      "epoch": 0.6666666666666666,
      "eval_loss": 2.744640588760376,
      "eval_runtime": 197.3554,
      "eval_samples_per_second": 10.134,
      "eval_steps_per_second": 1.267,
      "step": 1500
    },
    {
      "epoch": 0.6711111111111111,
      "grad_norm": 0.9587300419807434,
      "learning_rate": 3.322222222222222e-05,
      "loss": 2.6817,
      "step": 1510
    },
    {
      "epoch": 0.6755555555555556,
      "grad_norm": 0.9502821564674377,
      "learning_rate": 3.311111111111112e-05,
      "loss": 2.7515,
      "step": 1520
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.9076757431030273,
      "learning_rate": 3.3e-05,
      "loss": 2.7005,
      "step": 1530
    },
    {
      "epoch": 0.6844444444444444,
      "grad_norm": 0.9301269054412842,
      "learning_rate": 3.2888888888888894e-05,
      "loss": 2.8605,
      "step": 1540
    },
    {
      "epoch": 0.6888888888888889,
      "grad_norm": 0.8195439577102661,
      "learning_rate": 3.277777777777778e-05,
      "loss": 2.6908,
      "step": 1550
    },
    {
      "epoch": 0.6933333333333334,
      "grad_norm": 0.7542176842689514,
      "learning_rate": 3.266666666666667e-05,
      "loss": 2.7567,
      "step": 1560
    },
    {
      "epoch": 0.6977777777777778,
      "grad_norm": 0.9190207719802856,
      "learning_rate": 3.2555555555555555e-05,
      "loss": 2.6674,
      "step": 1570
    },
    {
      "epoch": 0.7022222222222222,
      "grad_norm": 1.1770470142364502,
      "learning_rate": 3.2444444444444446e-05,
      "loss": 2.686,
      "step": 1580
    },
    {
      "epoch": 0.7066666666666667,
      "grad_norm": 0.6972286105155945,
      "learning_rate": 3.233333333333333e-05,
      "loss": 2.6882,
      "step": 1590
    },
    {
      "epoch": 0.7111111111111111,
      "grad_norm": 0.864646852016449,
      "learning_rate": 3.222222222222223e-05,
      "loss": 2.5892,
      "step": 1600
    },
    {
      "epoch": 0.7111111111111111,
      "eval_loss": 2.7439045906066895,
      "eval_runtime": 197.5108,
      "eval_samples_per_second": 10.126,
      "eval_steps_per_second": 1.266,
      "step": 1600
    },
    {
      "epoch": 0.7155555555555555,
      "grad_norm": 0.8685358166694641,
      "learning_rate": 3.2111111111111114e-05,
      "loss": 2.681,
      "step": 1610
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.7742667198181152,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 2.7378,
      "step": 1620
    },
    {
      "epoch": 0.7244444444444444,
      "grad_norm": 0.7423231601715088,
      "learning_rate": 3.188888888888889e-05,
      "loss": 2.7419,
      "step": 1630
    },
    {
      "epoch": 0.7288888888888889,
      "grad_norm": 0.8788865208625793,
      "learning_rate": 3.177777777777778e-05,
      "loss": 2.7587,
      "step": 1640
    },
    {
      "epoch": 0.7333333333333333,
      "grad_norm": 0.9843416810035706,
      "learning_rate": 3.1666666666666666e-05,
      "loss": 2.9244,
      "step": 1650
    },
    {
      "epoch": 0.7377777777777778,
      "grad_norm": 0.7743030786514282,
      "learning_rate": 3.155555555555556e-05,
      "loss": 2.8052,
      "step": 1660
    },
    {
      "epoch": 0.7422222222222222,
      "grad_norm": 0.8351013660430908,
      "learning_rate": 3.144444444444445e-05,
      "loss": 2.67,
      "step": 1670
    },
    {
      "epoch": 0.7466666666666667,
      "grad_norm": 0.8786852359771729,
      "learning_rate": 3.1333333333333334e-05,
      "loss": 2.7831,
      "step": 1680
    },
    {
      "epoch": 0.7511111111111111,
      "grad_norm": 0.8547019362449646,
      "learning_rate": 3.1222222222222225e-05,
      "loss": 2.7053,
      "step": 1690
    },
    {
      "epoch": 0.7555555555555555,
      "grad_norm": 0.7061131596565247,
      "learning_rate": 3.111111111111111e-05,
      "loss": 2.7585,
      "step": 1700
    },
    {
      "epoch": 0.7555555555555555,
      "eval_loss": 2.741579532623291,
      "eval_runtime": 197.5578,
      "eval_samples_per_second": 10.124,
      "eval_steps_per_second": 1.265,
      "step": 1700
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.1384658813476562,
      "learning_rate": 3.1e-05,
      "loss": 2.6444,
      "step": 1710
    },
    {
      "epoch": 0.7644444444444445,
      "grad_norm": 0.7908799648284912,
      "learning_rate": 3.088888888888889e-05,
      "loss": 2.8512,
      "step": 1720
    },
    {
      "epoch": 0.7688888888888888,
      "grad_norm": 0.860514760017395,
      "learning_rate": 3.077777777777778e-05,
      "loss": 2.7274,
      "step": 1730
    },
    {
      "epoch": 0.7733333333333333,
      "grad_norm": 0.8110691905021667,
      "learning_rate": 3.066666666666667e-05,
      "loss": 2.697,
      "step": 1740
    },
    {
      "epoch": 0.7777777777777778,
      "grad_norm": 0.7930853366851807,
      "learning_rate": 3.055555555555556e-05,
      "loss": 2.7099,
      "step": 1750
    },
    {
      "epoch": 0.7822222222222223,
      "grad_norm": 0.821563184261322,
      "learning_rate": 3.044444444444445e-05,
      "loss": 2.7406,
      "step": 1760
    },
    {
      "epoch": 0.7866666666666666,
      "grad_norm": 1.022976279258728,
      "learning_rate": 3.0333333333333337e-05,
      "loss": 2.8365,
      "step": 1770
    },
    {
      "epoch": 0.7911111111111111,
      "grad_norm": 1.182708978652954,
      "learning_rate": 3.0222222222222225e-05,
      "loss": 2.672,
      "step": 1780
    },
    {
      "epoch": 0.7955555555555556,
      "grad_norm": 0.8680816292762756,
      "learning_rate": 3.0111111111111113e-05,
      "loss": 2.7485,
      "step": 1790
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.8422674536705017,
      "learning_rate": 3e-05,
      "loss": 2.6192,
      "step": 1800
    },
    {
      "epoch": 0.8,
      "eval_loss": 2.7386415004730225,
      "eval_runtime": 199.6951,
      "eval_samples_per_second": 10.015,
      "eval_steps_per_second": 1.252,
      "step": 1800
    },
    {
      "epoch": 0.8044444444444444,
      "grad_norm": 0.7679806351661682,
      "learning_rate": 2.988888888888889e-05,
      "loss": 2.6089,
      "step": 1810
    },
    {
      "epoch": 0.8088888888888889,
      "grad_norm": 0.7555769085884094,
      "learning_rate": 2.9777777777777777e-05,
      "loss": 2.6217,
      "step": 1820
    },
    {
      "epoch": 0.8133333333333334,
      "grad_norm": 1.0236183404922485,
      "learning_rate": 2.9666666666666672e-05,
      "loss": 2.8167,
      "step": 1830
    },
    {
      "epoch": 0.8177777777777778,
      "grad_norm": 0.8291633725166321,
      "learning_rate": 2.955555555555556e-05,
      "loss": 2.6416,
      "step": 1840
    },
    {
      "epoch": 0.8222222222222222,
      "grad_norm": 1.1037689447402954,
      "learning_rate": 2.9444444444444448e-05,
      "loss": 2.697,
      "step": 1850
    },
    {
      "epoch": 0.8266666666666667,
      "grad_norm": 0.7891042232513428,
      "learning_rate": 2.9333333333333336e-05,
      "loss": 2.6838,
      "step": 1860
    },
    {
      "epoch": 0.8311111111111111,
      "grad_norm": 0.8123503923416138,
      "learning_rate": 2.9222222222222224e-05,
      "loss": 2.6758,
      "step": 1870
    },
    {
      "epoch": 0.8355555555555556,
      "grad_norm": 0.7419880032539368,
      "learning_rate": 2.9111111111111112e-05,
      "loss": 2.7288,
      "step": 1880
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.954397439956665,
      "learning_rate": 2.9e-05,
      "loss": 2.7928,
      "step": 1890
    },
    {
      "epoch": 0.8444444444444444,
      "grad_norm": 0.9979373812675476,
      "learning_rate": 2.8888888888888888e-05,
      "loss": 2.7301,
      "step": 1900
    },
    {
      "epoch": 0.8444444444444444,
      "eval_loss": 2.737889051437378,
      "eval_runtime": 199.2243,
      "eval_samples_per_second": 10.039,
      "eval_steps_per_second": 1.255,
      "step": 1900
    },
    {
      "epoch": 0.8488888888888889,
      "grad_norm": 0.9021849632263184,
      "learning_rate": 2.877777777777778e-05,
      "loss": 2.7208,
      "step": 1910
    },
    {
      "epoch": 0.8533333333333334,
      "grad_norm": 0.7233775854110718,
      "learning_rate": 2.8666666666666668e-05,
      "loss": 2.6663,
      "step": 1920
    },
    {
      "epoch": 0.8577777777777778,
      "grad_norm": 0.772020697593689,
      "learning_rate": 2.855555555555556e-05,
      "loss": 2.7259,
      "step": 1930
    },
    {
      "epoch": 0.8622222222222222,
      "grad_norm": 0.7848647832870483,
      "learning_rate": 2.8444444444444447e-05,
      "loss": 2.7078,
      "step": 1940
    },
    {
      "epoch": 0.8666666666666667,
      "grad_norm": 0.8730045557022095,
      "learning_rate": 2.8333333333333335e-05,
      "loss": 2.7203,
      "step": 1950
    },
    {
      "epoch": 0.8711111111111111,
      "grad_norm": 0.9075590968132019,
      "learning_rate": 2.8222222222222223e-05,
      "loss": 2.7626,
      "step": 1960
    },
    {
      "epoch": 0.8755555555555555,
      "grad_norm": 0.8624074459075928,
      "learning_rate": 2.811111111111111e-05,
      "loss": 2.6672,
      "step": 1970
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.8246385455131531,
      "learning_rate": 2.8000000000000003e-05,
      "loss": 2.6846,
      "step": 1980
    },
    {
      "epoch": 0.8844444444444445,
      "grad_norm": 1.1866611242294312,
      "learning_rate": 2.788888888888889e-05,
      "loss": 2.6907,
      "step": 1990
    },
    {
      "epoch": 0.8888888888888888,
      "grad_norm": 0.8775323033332825,
      "learning_rate": 2.777777777777778e-05,
      "loss": 2.8143,
      "step": 2000
    },
    {
      "epoch": 0.8888888888888888,
      "eval_loss": 2.737161636352539,
      "eval_runtime": 197.2433,
      "eval_samples_per_second": 10.14,
      "eval_steps_per_second": 1.267,
      "step": 2000
    },
    {
      "epoch": 0.8933333333333333,
      "grad_norm": 0.8042116761207581,
      "learning_rate": 2.7666666666666667e-05,
      "loss": 2.7005,
      "step": 2010
    },
    {
      "epoch": 0.8977777777777778,
      "grad_norm": 0.9016651511192322,
      "learning_rate": 2.7555555555555555e-05,
      "loss": 2.6722,
      "step": 2020
    },
    {
      "epoch": 0.9022222222222223,
      "grad_norm": 0.8130889534950256,
      "learning_rate": 2.7444444444444443e-05,
      "loss": 2.7542,
      "step": 2030
    },
    {
      "epoch": 0.9066666666666666,
      "grad_norm": 0.8760853409767151,
      "learning_rate": 2.733333333333333e-05,
      "loss": 2.7266,
      "step": 2040
    },
    {
      "epoch": 0.9111111111111111,
      "grad_norm": 1.185054898262024,
      "learning_rate": 2.7222222222222223e-05,
      "loss": 2.7095,
      "step": 2050
    },
    {
      "epoch": 0.9155555555555556,
      "grad_norm": 1.0073621273040771,
      "learning_rate": 2.7111111111111114e-05,
      "loss": 2.7655,
      "step": 2060
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.8490132093429565,
      "learning_rate": 2.7000000000000002e-05,
      "loss": 2.7011,
      "step": 2070
    },
    {
      "epoch": 0.9244444444444444,
      "grad_norm": 0.7980822920799255,
      "learning_rate": 2.688888888888889e-05,
      "loss": 2.7207,
      "step": 2080
    },
    {
      "epoch": 0.9288888888888889,
      "grad_norm": 0.8180295825004578,
      "learning_rate": 2.677777777777778e-05,
      "loss": 2.7271,
      "step": 2090
    },
    {
      "epoch": 0.9333333333333333,
      "grad_norm": NaN,
      "learning_rate": 2.667777777777778e-05,
      "loss": 2.7217,
      "step": 2100
    },
    {
      "epoch": 0.9333333333333333,
      "eval_loss": 2.7371864318847656,
      "eval_runtime": 197.3393,
      "eval_samples_per_second": 10.135,
      "eval_steps_per_second": 1.267,
      "step": 2100
    },
    {
      "epoch": 0.9377777777777778,
      "grad_norm": 0.8920336365699768,
      "learning_rate": 2.6566666666666668e-05,
      "loss": 2.8276,
      "step": 2110
    },
    {
      "epoch": 0.9422222222222222,
      "grad_norm": 0.8435719609260559,
      "learning_rate": 2.6455555555555556e-05,
      "loss": 2.6743,
      "step": 2120
    },
    {
      "epoch": 0.9466666666666667,
      "grad_norm": 0.9013076424598694,
      "learning_rate": 2.6344444444444444e-05,
      "loss": 2.7891,
      "step": 2130
    },
    {
      "epoch": 0.9511111111111111,
      "grad_norm": 0.8817044496536255,
      "learning_rate": 2.6233333333333332e-05,
      "loss": 2.6456,
      "step": 2140
    },
    {
      "epoch": 0.9555555555555556,
      "grad_norm": 0.76483553647995,
      "learning_rate": 2.6122222222222227e-05,
      "loss": 2.6609,
      "step": 2150
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.0087084770202637,
      "learning_rate": 2.6011111111111115e-05,
      "loss": 2.7243,
      "step": 2160
    },
    {
      "epoch": 0.9644444444444444,
      "grad_norm": 0.8073261380195618,
      "learning_rate": 2.5900000000000003e-05,
      "loss": 2.733,
      "step": 2170
    },
    {
      "epoch": 0.9688888888888889,
      "grad_norm": 0.9919570684432983,
      "learning_rate": 2.578888888888889e-05,
      "loss": 2.6208,
      "step": 2180
    },
    {
      "epoch": 0.9733333333333334,
      "grad_norm": 0.9852652549743652,
      "learning_rate": 2.567777777777778e-05,
      "loss": 2.7103,
      "step": 2190
    },
    {
      "epoch": 0.9777777777777777,
      "grad_norm": 0.8214147686958313,
      "learning_rate": 2.5566666666666667e-05,
      "loss": 2.713,
      "step": 2200
    },
    {
      "epoch": 0.9777777777777777,
      "eval_loss": 2.734804630279541,
      "eval_runtime": 197.0539,
      "eval_samples_per_second": 10.15,
      "eval_steps_per_second": 1.269,
      "step": 2200
    },
    {
      "epoch": 0.9822222222222222,
      "grad_norm": 0.9704031944274902,
      "learning_rate": 2.5455555555555555e-05,
      "loss": 2.7368,
      "step": 2210
    },
    {
      "epoch": 0.9866666666666667,
      "grad_norm": 0.911129891872406,
      "learning_rate": 2.534444444444445e-05,
      "loss": 2.7436,
      "step": 2220
    },
    {
      "epoch": 0.9911111111111112,
      "grad_norm": 0.8469277620315552,
      "learning_rate": 2.5233333333333338e-05,
      "loss": 2.7613,
      "step": 2230
    },
    {
      "epoch": 0.9955555555555555,
      "grad_norm": 0.7130131125450134,
      "learning_rate": 2.5122222222222226e-05,
      "loss": 2.6347,
      "step": 2240
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.8743430972099304,
      "learning_rate": 2.5011111111111114e-05,
      "loss": 2.627,
      "step": 2250
    },
    {
      "epoch": 1.0044444444444445,
      "grad_norm": 0.8141344785690308,
      "learning_rate": 2.4900000000000002e-05,
      "loss": 2.7571,
      "step": 2260
    },
    {
      "epoch": 1.008888888888889,
      "grad_norm": 0.801089346408844,
      "learning_rate": 2.478888888888889e-05,
      "loss": 2.654,
      "step": 2270
    },
    {
      "epoch": 1.0133333333333334,
      "grad_norm": 1.0077158212661743,
      "learning_rate": 2.467777777777778e-05,
      "loss": 2.7369,
      "step": 2280
    },
    {
      "epoch": 1.0177777777777777,
      "grad_norm": 0.8295379877090454,
      "learning_rate": 2.456666666666667e-05,
      "loss": 2.6121,
      "step": 2290
    },
    {
      "epoch": 1.0222222222222221,
      "grad_norm": 0.9893662333488464,
      "learning_rate": 2.4455555555555558e-05,
      "loss": 2.7599,
      "step": 2300
    },
    {
      "epoch": 1.0222222222222221,
      "eval_loss": 2.733578681945801,
      "eval_runtime": 196.7894,
      "eval_samples_per_second": 10.163,
      "eval_steps_per_second": 1.27,
      "step": 2300
    },
    {
      "epoch": 1.0266666666666666,
      "grad_norm": 0.969426691532135,
      "learning_rate": 2.4344444444444446e-05,
      "loss": 2.7337,
      "step": 2310
    },
    {
      "epoch": 1.031111111111111,
      "grad_norm": 0.8692841529846191,
      "learning_rate": 2.4233333333333337e-05,
      "loss": 2.6589,
      "step": 2320
    },
    {
      "epoch": 1.0355555555555556,
      "grad_norm": 0.8805749416351318,
      "learning_rate": 2.4122222222222225e-05,
      "loss": 2.7119,
      "step": 2330
    },
    {
      "epoch": 1.04,
      "grad_norm": 1.4051684141159058,
      "learning_rate": 2.4011111111111113e-05,
      "loss": 2.6731,
      "step": 2340
    },
    {
      "epoch": 1.0444444444444445,
      "grad_norm": 0.7988607883453369,
      "learning_rate": 2.39e-05,
      "loss": 2.7214,
      "step": 2350
    },
    {
      "epoch": 1.048888888888889,
      "grad_norm": 0.9225556254386902,
      "learning_rate": 2.378888888888889e-05,
      "loss": 2.7784,
      "step": 2360
    },
    {
      "epoch": 1.0533333333333332,
      "grad_norm": 0.8658252954483032,
      "learning_rate": 2.3677777777777778e-05,
      "loss": 2.664,
      "step": 2370
    },
    {
      "epoch": 1.0577777777777777,
      "grad_norm": 0.926617443561554,
      "learning_rate": 2.3566666666666666e-05,
      "loss": 2.7076,
      "step": 2380
    },
    {
      "epoch": 1.0622222222222222,
      "grad_norm": 0.9516193270683289,
      "learning_rate": 2.3455555555555557e-05,
      "loss": 2.7317,
      "step": 2390
    },
    {
      "epoch": 1.0666666666666667,
      "grad_norm": 0.9137372374534607,
      "learning_rate": 2.3344444444444445e-05,
      "loss": 2.6655,
      "step": 2400
    },
    {
      "epoch": 1.0666666666666667,
      "eval_loss": 2.7322447299957275,
      "eval_runtime": 197.359,
      "eval_samples_per_second": 10.134,
      "eval_steps_per_second": 1.267,
      "step": 2400
    },
    {
      "epoch": 1.0711111111111111,
      "grad_norm": 0.8186412453651428,
      "learning_rate": 2.3233333333333333e-05,
      "loss": 2.6539,
      "step": 2410
    },
    {
      "epoch": 1.0755555555555556,
      "grad_norm": 0.7994779944419861,
      "learning_rate": 2.312222222222222e-05,
      "loss": 2.5791,
      "step": 2420
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.9610079526901245,
      "learning_rate": 2.301111111111111e-05,
      "loss": 2.7275,
      "step": 2430
    },
    {
      "epoch": 1.0844444444444445,
      "grad_norm": 0.8033866286277771,
      "learning_rate": 2.29e-05,
      "loss": 2.6823,
      "step": 2440
    },
    {
      "epoch": 1.0888888888888888,
      "grad_norm": 1.0396525859832764,
      "learning_rate": 2.278888888888889e-05,
      "loss": 2.6324,
      "step": 2450
    },
    {
      "epoch": 1.0933333333333333,
      "grad_norm": 0.9646901488304138,
      "learning_rate": 2.2677777777777777e-05,
      "loss": 2.7309,
      "step": 2460
    },
    {
      "epoch": 1.0977777777777777,
      "grad_norm": 0.8176262378692627,
      "learning_rate": 2.2566666666666665e-05,
      "loss": 2.7551,
      "step": 2470
    },
    {
      "epoch": 1.1022222222222222,
      "grad_norm": 0.8441779017448425,
      "learning_rate": 2.2455555555555557e-05,
      "loss": 2.6721,
      "step": 2480
    },
    {
      "epoch": 1.1066666666666667,
      "grad_norm": 0.7010478377342224,
      "learning_rate": 2.2344444444444445e-05,
      "loss": 2.6717,
      "step": 2490
    },
    {
      "epoch": 1.1111111111111112,
      "grad_norm": 0.9493184685707092,
      "learning_rate": 2.2233333333333333e-05,
      "loss": 2.8249,
      "step": 2500
    },
    {
      "epoch": 1.1111111111111112,
      "eval_loss": 2.731576681137085,
      "eval_runtime": 197.1955,
      "eval_samples_per_second": 10.142,
      "eval_steps_per_second": 1.268,
      "step": 2500
    },
    {
      "epoch": 1.1155555555555556,
      "grad_norm": 1.1923129558563232,
      "learning_rate": 2.212222222222222e-05,
      "loss": 2.7363,
      "step": 2510
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.8914772272109985,
      "learning_rate": 2.2011111111111112e-05,
      "loss": 2.7119,
      "step": 2520
    },
    {
      "epoch": 1.1244444444444444,
      "grad_norm": 0.9834191203117371,
      "learning_rate": 2.19e-05,
      "loss": 2.7709,
      "step": 2530
    },
    {
      "epoch": 1.1288888888888888,
      "grad_norm": 0.8989059329032898,
      "learning_rate": 2.178888888888889e-05,
      "loss": 2.6167,
      "step": 2540
    },
    {
      "epoch": 1.1333333333333333,
      "grad_norm": 0.9759187698364258,
      "learning_rate": 2.167777777777778e-05,
      "loss": 2.6281,
      "step": 2550
    },
    {
      "epoch": 1.1377777777777778,
      "grad_norm": 0.912720799446106,
      "learning_rate": 2.1566666666666668e-05,
      "loss": 2.6144,
      "step": 2560
    },
    {
      "epoch": 1.1422222222222222,
      "grad_norm": 0.8649840950965881,
      "learning_rate": 2.1455555555555556e-05,
      "loss": 2.7123,
      "step": 2570
    },
    {
      "epoch": 1.1466666666666667,
      "grad_norm": 0.8597713112831116,
      "learning_rate": 2.1344444444444444e-05,
      "loss": 2.7554,
      "step": 2580
    },
    {
      "epoch": 1.1511111111111112,
      "grad_norm": 0.9511238932609558,
      "learning_rate": 2.1233333333333336e-05,
      "loss": 2.637,
      "step": 2590
    },
    {
      "epoch": 1.1555555555555554,
      "grad_norm": 1.2281888723373413,
      "learning_rate": 2.1122222222222224e-05,
      "loss": 2.7542,
      "step": 2600
    },
    {
      "epoch": 1.1555555555555554,
      "eval_loss": 2.731248617172241,
      "eval_runtime": 198.3491,
      "eval_samples_per_second": 10.083,
      "eval_steps_per_second": 1.26,
      "step": 2600
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.9372813701629639,
      "learning_rate": 2.1011111111111112e-05,
      "loss": 2.6506,
      "step": 2610
    },
    {
      "epoch": 1.1644444444444444,
      "grad_norm": 0.7991012334823608,
      "learning_rate": 2.09e-05,
      "loss": 2.7575,
      "step": 2620
    },
    {
      "epoch": 1.1688888888888889,
      "grad_norm": 0.8372776508331299,
      "learning_rate": 2.078888888888889e-05,
      "loss": 2.7193,
      "step": 2630
    },
    {
      "epoch": 1.1733333333333333,
      "grad_norm": 0.9418508410453796,
      "learning_rate": 2.067777777777778e-05,
      "loss": 2.6589,
      "step": 2640
    },
    {
      "epoch": 1.1777777777777778,
      "grad_norm": 0.9821892976760864,
      "learning_rate": 2.0566666666666667e-05,
      "loss": 2.6433,
      "step": 2650
    },
    {
      "epoch": 1.1822222222222223,
      "grad_norm": 0.7867190837860107,
      "learning_rate": 2.0455555555555555e-05,
      "loss": 2.6683,
      "step": 2660
    },
    {
      "epoch": 1.1866666666666668,
      "grad_norm": 0.8745481371879578,
      "learning_rate": 2.0344444444444447e-05,
      "loss": 2.7065,
      "step": 2670
    },
    {
      "epoch": 1.1911111111111112,
      "grad_norm": 0.8847087621688843,
      "learning_rate": 2.0233333333333335e-05,
      "loss": 2.7272,
      "step": 2680
    },
    {
      "epoch": 1.1955555555555555,
      "grad_norm": 0.9400413632392883,
      "learning_rate": 2.0122222222222223e-05,
      "loss": 2.6731,
      "step": 2690
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.0783255100250244,
      "learning_rate": 2.001111111111111e-05,
      "loss": 2.6856,
      "step": 2700
    },
    {
      "epoch": 1.2,
      "eval_loss": 2.730520009994507,
      "eval_runtime": 197.1505,
      "eval_samples_per_second": 10.145,
      "eval_steps_per_second": 1.268,
      "step": 2700
    },
    {
      "epoch": 1.2044444444444444,
      "grad_norm": 0.8887600302696228,
      "learning_rate": 1.9900000000000003e-05,
      "loss": 2.6782,
      "step": 2710
    },
    {
      "epoch": 1.208888888888889,
      "grad_norm": 1.191519856452942,
      "learning_rate": 1.978888888888889e-05,
      "loss": 2.6638,
      "step": 2720
    },
    {
      "epoch": 1.2133333333333334,
      "grad_norm": 0.7959201335906982,
      "learning_rate": 1.967777777777778e-05,
      "loss": 2.7084,
      "step": 2730
    },
    {
      "epoch": 1.2177777777777778,
      "grad_norm": 0.9018886089324951,
      "learning_rate": 1.9566666666666667e-05,
      "loss": 2.771,
      "step": 2740
    },
    {
      "epoch": 1.2222222222222223,
      "grad_norm": 0.9118149280548096,
      "learning_rate": 1.9455555555555558e-05,
      "loss": 2.6815,
      "step": 2750
    },
    {
      "epoch": 1.2266666666666666,
      "grad_norm": 0.9878263473510742,
      "learning_rate": 1.9344444444444446e-05,
      "loss": 2.6739,
      "step": 2760
    },
    {
      "epoch": 1.231111111111111,
      "grad_norm": 0.8934276103973389,
      "learning_rate": 1.9233333333333334e-05,
      "loss": 2.6897,
      "step": 2770
    },
    {
      "epoch": 1.2355555555555555,
      "grad_norm": 0.9005341529846191,
      "learning_rate": 1.9122222222222222e-05,
      "loss": 2.7658,
      "step": 2780
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.901452362537384,
      "learning_rate": 1.9011111111111114e-05,
      "loss": 2.7186,
      "step": 2790
    },
    {
      "epoch": 1.2444444444444445,
      "grad_norm": 0.8630498051643372,
      "learning_rate": 1.8900000000000002e-05,
      "loss": 2.6629,
      "step": 2800
    },
    {
      "epoch": 1.2444444444444445,
      "eval_loss": 2.7293879985809326,
      "eval_runtime": 196.7527,
      "eval_samples_per_second": 10.165,
      "eval_steps_per_second": 1.271,
      "step": 2800
    },
    {
      "epoch": 1.248888888888889,
      "grad_norm": 1.1974701881408691,
      "learning_rate": 1.878888888888889e-05,
      "loss": 2.7645,
      "step": 2810
    },
    {
      "epoch": 1.2533333333333334,
      "grad_norm": 1.1554003953933716,
      "learning_rate": 1.8677777777777778e-05,
      "loss": 2.6284,
      "step": 2820
    },
    {
      "epoch": 1.2577777777777777,
      "grad_norm": 0.9141109585762024,
      "learning_rate": 1.856666666666667e-05,
      "loss": 2.6837,
      "step": 2830
    },
    {
      "epoch": 1.2622222222222224,
      "grad_norm": 0.8459830284118652,
      "learning_rate": 1.8455555555555558e-05,
      "loss": 2.635,
      "step": 2840
    },
    {
      "epoch": 1.2666666666666666,
      "grad_norm": 0.9457470774650574,
      "learning_rate": 1.8344444444444446e-05,
      "loss": 2.638,
      "step": 2850
    },
    {
      "epoch": 1.271111111111111,
      "grad_norm": 0.9454271197319031,
      "learning_rate": 1.8233333333333334e-05,
      "loss": 2.6107,
      "step": 2860
    },
    {
      "epoch": 1.2755555555555556,
      "grad_norm": 1.0711489915847778,
      "learning_rate": 1.8122222222222225e-05,
      "loss": 2.7522,
      "step": 2870
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.0293612480163574,
      "learning_rate": 1.8011111111111113e-05,
      "loss": 2.634,
      "step": 2880
    },
    {
      "epoch": 1.2844444444444445,
      "grad_norm": 0.9079248905181885,
      "learning_rate": 1.79e-05,
      "loss": 2.67,
      "step": 2890
    },
    {
      "epoch": 1.2888888888888888,
      "grad_norm": 1.1587713956832886,
      "learning_rate": 1.778888888888889e-05,
      "loss": 2.71,
      "step": 2900
    },
    {
      "epoch": 1.2888888888888888,
      "eval_loss": 2.72877836227417,
      "eval_runtime": 198.5104,
      "eval_samples_per_second": 10.075,
      "eval_steps_per_second": 1.259,
      "step": 2900
    },
    {
      "epoch": 1.2933333333333334,
      "grad_norm": 1.1606078147888184,
      "learning_rate": 1.7677777777777778e-05,
      "loss": 2.6978,
      "step": 2910
    },
    {
      "epoch": 1.2977777777777777,
      "grad_norm": 1.1298834085464478,
      "learning_rate": 1.756666666666667e-05,
      "loss": 2.7901,
      "step": 2920
    },
    {
      "epoch": 1.3022222222222222,
      "grad_norm": 0.9785627126693726,
      "learning_rate": 1.7455555555555557e-05,
      "loss": 2.7261,
      "step": 2930
    },
    {
      "epoch": 1.3066666666666666,
      "grad_norm": 0.8871484994888306,
      "learning_rate": 1.7344444444444445e-05,
      "loss": 2.7412,
      "step": 2940
    },
    {
      "epoch": 1.3111111111111111,
      "grad_norm": 0.8254889249801636,
      "learning_rate": 1.7233333333333333e-05,
      "loss": 2.7413,
      "step": 2950
    },
    {
      "epoch": 1.3155555555555556,
      "grad_norm": 0.9633082747459412,
      "learning_rate": 1.712222222222222e-05,
      "loss": 2.7628,
      "step": 2960
    },
    {
      "epoch": 1.32,
      "grad_norm": 1.0370053052902222,
      "learning_rate": 1.701111111111111e-05,
      "loss": 2.6008,
      "step": 2970
    },
    {
      "epoch": 1.3244444444444445,
      "grad_norm": 0.9036823511123657,
      "learning_rate": 1.69e-05,
      "loss": 2.7354,
      "step": 2980
    },
    {
      "epoch": 1.3288888888888888,
      "grad_norm": 0.8951491117477417,
      "learning_rate": 1.678888888888889e-05,
      "loss": 2.7452,
      "step": 2990
    },
    {
      "epoch": 1.3333333333333333,
      "grad_norm": 0.9360761046409607,
      "learning_rate": 1.6677777777777777e-05,
      "loss": 2.7309,
      "step": 3000
    },
    {
      "epoch": 1.3333333333333333,
      "eval_loss": 2.7274560928344727,
      "eval_runtime": 197.3726,
      "eval_samples_per_second": 10.133,
      "eval_steps_per_second": 1.267,
      "step": 3000
    },
    {
      "epoch": 1.3377777777777777,
      "grad_norm": 1.0446739196777344,
      "learning_rate": 1.6566666666666665e-05,
      "loss": 2.7331,
      "step": 3010
    },
    {
      "epoch": 1.3422222222222222,
      "grad_norm": 1.0030707120895386,
      "learning_rate": 1.6455555555555556e-05,
      "loss": 2.7252,
      "step": 3020
    },
    {
      "epoch": 1.3466666666666667,
      "grad_norm": 1.1620720624923706,
      "learning_rate": 1.6344444444444445e-05,
      "loss": 2.7353,
      "step": 3030
    },
    {
      "epoch": 1.3511111111111112,
      "grad_norm": 1.0997377634048462,
      "learning_rate": 1.6233333333333333e-05,
      "loss": 2.7172,
      "step": 3040
    },
    {
      "epoch": 1.3555555555555556,
      "grad_norm": 1.0740940570831299,
      "learning_rate": 1.612222222222222e-05,
      "loss": 2.6386,
      "step": 3050
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 1.1605974435806274,
      "learning_rate": 1.6011111111111112e-05,
      "loss": 2.6104,
      "step": 3060
    },
    {
      "epoch": 1.3644444444444446,
      "grad_norm": 1.064174771308899,
      "learning_rate": 1.59e-05,
      "loss": 2.6319,
      "step": 3070
    },
    {
      "epoch": 1.3688888888888888,
      "grad_norm": 0.9475700855255127,
      "learning_rate": 1.5788888888888888e-05,
      "loss": 2.6947,
      "step": 3080
    },
    {
      "epoch": 1.3733333333333333,
      "grad_norm": 1.1437063217163086,
      "learning_rate": 1.5677777777777776e-05,
      "loss": 2.7151,
      "step": 3090
    },
    {
      "epoch": 1.3777777777777778,
      "grad_norm": 1.1946369409561157,
      "learning_rate": 1.5566666666666668e-05,
      "loss": 2.7005,
      "step": 3100
    },
    {
      "epoch": 1.3777777777777778,
      "eval_loss": 2.7267520427703857,
      "eval_runtime": 197.0047,
      "eval_samples_per_second": 10.152,
      "eval_steps_per_second": 1.269,
      "step": 3100
    },
    {
      "epoch": 1.3822222222222222,
      "grad_norm": 1.033565878868103,
      "learning_rate": 1.5455555555555556e-05,
      "loss": 2.729,
      "step": 3110
    },
    {
      "epoch": 1.3866666666666667,
      "grad_norm": 0.9409695267677307,
      "learning_rate": 1.5344444444444444e-05,
      "loss": 2.6874,
      "step": 3120
    },
    {
      "epoch": 1.3911111111111112,
      "grad_norm": 0.9984094500541687,
      "learning_rate": 1.5233333333333332e-05,
      "loss": 2.7535,
      "step": 3130
    },
    {
      "epoch": 1.3955555555555557,
      "grad_norm": 1.003468632698059,
      "learning_rate": 1.5122222222222224e-05,
      "loss": 2.67,
      "step": 3140
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.0858134031295776,
      "learning_rate": 1.5011111111111112e-05,
      "loss": 2.6906,
      "step": 3150
    },
    {
      "epoch": 1.4044444444444444,
      "grad_norm": 0.9950515031814575,
      "learning_rate": 1.49e-05,
      "loss": 2.7137,
      "step": 3160
    },
    {
      "epoch": 1.4088888888888889,
      "grad_norm": 1.062671184539795,
      "learning_rate": 1.4788888888888888e-05,
      "loss": 2.7315,
      "step": 3170
    },
    {
      "epoch": 1.4133333333333333,
      "grad_norm": 1.269963264465332,
      "learning_rate": 1.467777777777778e-05,
      "loss": 2.6968,
      "step": 3180
    },
    {
      "epoch": 1.4177777777777778,
      "grad_norm": 0.99742192029953,
      "learning_rate": 1.4566666666666667e-05,
      "loss": 2.828,
      "step": 3190
    },
    {
      "epoch": 1.4222222222222223,
      "grad_norm": 0.9057649374008179,
      "learning_rate": 1.4455555555555555e-05,
      "loss": 2.6702,
      "step": 3200
    },
    {
      "epoch": 1.4222222222222223,
      "eval_loss": 2.72623348236084,
      "eval_runtime": 196.9195,
      "eval_samples_per_second": 10.156,
      "eval_steps_per_second": 1.27,
      "step": 3200
    },
    {
      "epoch": 1.4266666666666667,
      "grad_norm": 0.7733312249183655,
      "learning_rate": 1.4344444444444447e-05,
      "loss": 2.6673,
      "step": 3210
    },
    {
      "epoch": 1.431111111111111,
      "grad_norm": 0.9983717203140259,
      "learning_rate": 1.4233333333333335e-05,
      "loss": 2.7044,
      "step": 3220
    },
    {
      "epoch": 1.4355555555555555,
      "grad_norm": 0.9133080244064331,
      "learning_rate": 1.4122222222222223e-05,
      "loss": 2.7072,
      "step": 3230
    },
    {
      "epoch": 1.44,
      "grad_norm": 1.0271601676940918,
      "learning_rate": 1.4011111111111111e-05,
      "loss": 2.6541,
      "step": 3240
    },
    {
      "epoch": 1.4444444444444444,
      "grad_norm": 0.9095109701156616,
      "learning_rate": 1.3900000000000002e-05,
      "loss": 2.6551,
      "step": 3250
    },
    {
      "epoch": 1.448888888888889,
      "grad_norm": 1.085852026939392,
      "learning_rate": 1.378888888888889e-05,
      "loss": 2.68,
      "step": 3260
    },
    {
      "epoch": 1.4533333333333334,
      "grad_norm": 1.024387001991272,
      "learning_rate": 1.3677777777777779e-05,
      "loss": 2.6421,
      "step": 3270
    },
    {
      "epoch": 1.4577777777777778,
      "grad_norm": 1.195678472518921,
      "learning_rate": 1.3566666666666667e-05,
      "loss": 2.6694,
      "step": 3280
    },
    {
      "epoch": 1.462222222222222,
      "grad_norm": 0.9430280327796936,
      "learning_rate": 1.3455555555555558e-05,
      "loss": 2.6841,
      "step": 3290
    },
    {
      "epoch": 1.4666666666666668,
      "grad_norm": 0.8570297360420227,
      "learning_rate": 1.3344444444444446e-05,
      "loss": 2.7397,
      "step": 3300
    },
    {
      "epoch": 1.4666666666666668,
      "eval_loss": 2.7253832817077637,
      "eval_runtime": 196.0891,
      "eval_samples_per_second": 10.199,
      "eval_steps_per_second": 1.275,
      "step": 3300
    },
    {
      "epoch": 1.471111111111111,
      "grad_norm": 1.0277965068817139,
      "learning_rate": 1.3233333333333334e-05,
      "loss": 2.5652,
      "step": 3310
    },
    {
      "epoch": 1.4755555555555555,
      "grad_norm": 0.938668966293335,
      "learning_rate": 1.3122222222222222e-05,
      "loss": 2.609,
      "step": 3320
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.0861294269561768,
      "learning_rate": 1.3011111111111112e-05,
      "loss": 2.7328,
      "step": 3330
    },
    {
      "epoch": 1.4844444444444445,
      "grad_norm": 0.8601526618003845,
      "learning_rate": 1.29e-05,
      "loss": 2.69,
      "step": 3340
    },
    {
      "epoch": 1.488888888888889,
      "grad_norm": 1.016329288482666,
      "learning_rate": 1.278888888888889e-05,
      "loss": 2.5891,
      "step": 3350
    },
    {
      "epoch": 1.4933333333333334,
      "grad_norm": 0.99739009141922,
      "learning_rate": 1.2677777777777778e-05,
      "loss": 2.7193,
      "step": 3360
    },
    {
      "epoch": 1.4977777777777779,
      "grad_norm": 0.9909920692443848,
      "learning_rate": 1.2566666666666668e-05,
      "loss": 2.6104,
      "step": 3370
    },
    {
      "epoch": 1.5022222222222221,
      "grad_norm": 0.9990460872650146,
      "learning_rate": 1.2455555555555556e-05,
      "loss": 2.6678,
      "step": 3380
    },
    {
      "epoch": 1.5066666666666668,
      "grad_norm": 0.9843689799308777,
      "learning_rate": 1.2344444444444444e-05,
      "loss": 2.6503,
      "step": 3390
    },
    {
      "epoch": 1.511111111111111,
      "grad_norm": 1.1012579202651978,
      "learning_rate": 1.2233333333333334e-05,
      "loss": 2.6671,
      "step": 3400
    },
    {
      "epoch": 1.511111111111111,
      "eval_loss": 2.724902868270874,
      "eval_runtime": 197.5756,
      "eval_samples_per_second": 10.123,
      "eval_steps_per_second": 1.265,
      "step": 3400
    },
    {
      "epoch": 1.5155555555555555,
      "grad_norm": 0.896770715713501,
      "learning_rate": 1.2122222222222222e-05,
      "loss": 2.7253,
      "step": 3410
    },
    {
      "epoch": 1.52,
      "grad_norm": 1.2382434606552124,
      "learning_rate": 1.2011111111111111e-05,
      "loss": 2.7582,
      "step": 3420
    },
    {
      "epoch": 1.5244444444444445,
      "grad_norm": 1.0249861478805542,
      "learning_rate": 1.19e-05,
      "loss": 2.6984,
      "step": 3430
    },
    {
      "epoch": 1.528888888888889,
      "grad_norm": 0.7650458812713623,
      "learning_rate": 1.178888888888889e-05,
      "loss": 2.6463,
      "step": 3440
    },
    {
      "epoch": 1.5333333333333332,
      "grad_norm": 1.1462148427963257,
      "learning_rate": 1.1677777777777777e-05,
      "loss": 2.6749,
      "step": 3450
    },
    {
      "epoch": 1.537777777777778,
      "grad_norm": 0.9831725358963013,
      "learning_rate": 1.1566666666666667e-05,
      "loss": 2.7397,
      "step": 3460
    },
    {
      "epoch": 1.5422222222222222,
      "grad_norm": 0.9978287816047668,
      "learning_rate": 1.1455555555555555e-05,
      "loss": 2.6223,
      "step": 3470
    },
    {
      "epoch": 1.5466666666666666,
      "grad_norm": 1.1850234270095825,
      "learning_rate": 1.1344444444444445e-05,
      "loss": 2.6378,
      "step": 3480
    },
    {
      "epoch": 1.551111111111111,
      "grad_norm": 1.1043126583099365,
      "learning_rate": 1.1233333333333333e-05,
      "loss": 2.6299,
      "step": 3490
    },
    {
      "epoch": 1.5555555555555556,
      "grad_norm": 0.9437627792358398,
      "learning_rate": 1.1122222222222223e-05,
      "loss": 2.6612,
      "step": 3500
    },
    {
      "epoch": 1.5555555555555556,
      "eval_loss": 2.7245395183563232,
      "eval_runtime": 196.1779,
      "eval_samples_per_second": 10.195,
      "eval_steps_per_second": 1.274,
      "step": 3500
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.9549217820167542,
      "learning_rate": 1.1011111111111113e-05,
      "loss": 2.7331,
      "step": 3510
    },
    {
      "epoch": 1.5644444444444443,
      "grad_norm": 1.040300726890564,
      "learning_rate": 1.09e-05,
      "loss": 2.6938,
      "step": 3520
    },
    {
      "epoch": 1.568888888888889,
      "grad_norm": 0.8140577673912048,
      "learning_rate": 1.078888888888889e-05,
      "loss": 2.7365,
      "step": 3530
    },
    {
      "epoch": 1.5733333333333333,
      "grad_norm": 0.9907304644584656,
      "learning_rate": 1.0677777777777779e-05,
      "loss": 2.6447,
      "step": 3540
    },
    {
      "epoch": 1.5777777777777777,
      "grad_norm": 1.0533446073532104,
      "learning_rate": 1.0566666666666668e-05,
      "loss": 2.6894,
      "step": 3550
    },
    {
      "epoch": 1.5822222222222222,
      "grad_norm": 0.9114788174629211,
      "learning_rate": 1.0455555555555556e-05,
      "loss": 2.6609,
      "step": 3560
    },
    {
      "epoch": 1.5866666666666667,
      "grad_norm": 1.0169702768325806,
      "learning_rate": 1.0344444444444446e-05,
      "loss": 2.5823,
      "step": 3570
    },
    {
      "epoch": 1.5911111111111111,
      "grad_norm": 1.0333526134490967,
      "learning_rate": 1.0233333333333334e-05,
      "loss": 2.7781,
      "step": 3580
    },
    {
      "epoch": 1.5955555555555554,
      "grad_norm": 1.019770860671997,
      "learning_rate": 1.0122222222222224e-05,
      "loss": 2.609,
      "step": 3590
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.2120734453201294,
      "learning_rate": 1.0011111111111112e-05,
      "loss": 2.6038,
      "step": 3600
    },
    {
      "epoch": 1.6,
      "eval_loss": 2.7238411903381348,
      "eval_runtime": 196.3818,
      "eval_samples_per_second": 10.184,
      "eval_steps_per_second": 1.273,
      "step": 3600
    },
    {
      "epoch": 1.6044444444444443,
      "grad_norm": 1.1161175966262817,
      "learning_rate": 9.900000000000002e-06,
      "loss": 2.6896,
      "step": 3610
    },
    {
      "epoch": 1.608888888888889,
      "grad_norm": 0.852096676826477,
      "learning_rate": 9.78888888888889e-06,
      "loss": 2.6908,
      "step": 3620
    },
    {
      "epoch": 1.6133333333333333,
      "grad_norm": 0.9533377885818481,
      "learning_rate": 9.677777777777778e-06,
      "loss": 2.6847,
      "step": 3630
    },
    {
      "epoch": 1.6177777777777778,
      "grad_norm": 0.9556776285171509,
      "learning_rate": 9.566666666666666e-06,
      "loss": 2.773,
      "step": 3640
    },
    {
      "epoch": 1.6222222222222222,
      "grad_norm": 0.9924883246421814,
      "learning_rate": 9.455555555555556e-06,
      "loss": 2.735,
      "step": 3650
    },
    {
      "epoch": 1.6266666666666667,
      "grad_norm": 1.1512048244476318,
      "learning_rate": 9.344444444444444e-06,
      "loss": 2.649,
      "step": 3660
    },
    {
      "epoch": 1.6311111111111112,
      "grad_norm": 1.0504552125930786,
      "learning_rate": 9.233333333333334e-06,
      "loss": 2.7002,
      "step": 3670
    },
    {
      "epoch": 1.6355555555555554,
      "grad_norm": 2.571682929992676,
      "learning_rate": 9.122222222222222e-06,
      "loss": 2.6,
      "step": 3680
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 1.075952172279358,
      "learning_rate": 9.011111111111111e-06,
      "loss": 2.6427,
      "step": 3690
    },
    {
      "epoch": 1.6444444444444444,
      "grad_norm": 1.051894187927246,
      "learning_rate": 8.9e-06,
      "loss": 2.6493,
      "step": 3700
    },
    {
      "epoch": 1.6444444444444444,
      "eval_loss": 2.72367000579834,
      "eval_runtime": 196.3161,
      "eval_samples_per_second": 10.188,
      "eval_steps_per_second": 1.273,
      "step": 3700
    },
    {
      "epoch": 1.6488888888888888,
      "grad_norm": 0.8742319345474243,
      "learning_rate": 8.78888888888889e-06,
      "loss": 2.6976,
      "step": 3710
    },
    {
      "epoch": 1.6533333333333333,
      "grad_norm": 1.0156642198562622,
      "learning_rate": 8.677777777777777e-06,
      "loss": 2.7559,
      "step": 3720
    },
    {
      "epoch": 1.6577777777777778,
      "grad_norm": 0.9127671718597412,
      "learning_rate": 8.566666666666667e-06,
      "loss": 2.6756,
      "step": 3730
    },
    {
      "epoch": 1.6622222222222223,
      "grad_norm": 0.9408277273178101,
      "learning_rate": 8.455555555555555e-06,
      "loss": 2.6122,
      "step": 3740
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 0.9269084930419922,
      "learning_rate": 8.344444444444445e-06,
      "loss": 2.6534,
      "step": 3750
    },
    {
      "epoch": 1.6711111111111112,
      "grad_norm": 0.9840613603591919,
      "learning_rate": 8.233333333333333e-06,
      "loss": 2.5385,
      "step": 3760
    },
    {
      "epoch": 1.6755555555555555,
      "grad_norm": 1.0504993200302124,
      "learning_rate": 8.122222222222223e-06,
      "loss": 2.6831,
      "step": 3770
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 1.0182121992111206,
      "learning_rate": 8.01111111111111e-06,
      "loss": 2.773,
      "step": 3780
    },
    {
      "epoch": 1.6844444444444444,
      "grad_norm": 1.0854991674423218,
      "learning_rate": 7.9e-06,
      "loss": 2.578,
      "step": 3790
    },
    {
      "epoch": 1.6888888888888889,
      "grad_norm": 1.1974848508834839,
      "learning_rate": 7.788888888888889e-06,
      "loss": 2.6322,
      "step": 3800
    },
    {
      "epoch": 1.6888888888888889,
      "eval_loss": 2.7230100631713867,
      "eval_runtime": 196.2735,
      "eval_samples_per_second": 10.19,
      "eval_steps_per_second": 1.274,
      "step": 3800
    },
    {
      "epoch": 1.6933333333333334,
      "grad_norm": 0.9526089429855347,
      "learning_rate": 7.677777777777778e-06,
      "loss": 2.6145,
      "step": 3810
    },
    {
      "epoch": 1.6977777777777778,
      "grad_norm": 1.000848650932312,
      "learning_rate": 7.5666666666666665e-06,
      "loss": 2.7215,
      "step": 3820
    },
    {
      "epoch": 1.7022222222222223,
      "grad_norm": 2.1919071674346924,
      "learning_rate": 7.455555555555556e-06,
      "loss": 2.6802,
      "step": 3830
    },
    {
      "epoch": 1.7066666666666666,
      "grad_norm": 0.9179748296737671,
      "learning_rate": 7.344444444444445e-06,
      "loss": 2.7598,
      "step": 3840
    },
    {
      "epoch": 1.7111111111111112,
      "grad_norm": 1.2124205827713013,
      "learning_rate": 7.233333333333333e-06,
      "loss": 2.6603,
      "step": 3850
    },
    {
      "epoch": 1.7155555555555555,
      "grad_norm": 0.8928720951080322,
      "learning_rate": 7.122222222222223e-06,
      "loss": 2.6486,
      "step": 3860
    },
    {
      "epoch": 1.72,
      "grad_norm": 1.026089072227478,
      "learning_rate": 7.011111111111111e-06,
      "loss": 2.7549,
      "step": 3870
    },
    {
      "epoch": 1.7244444444444444,
      "grad_norm": 1.2104412317276,
      "learning_rate": 6.900000000000001e-06,
      "loss": 2.7567,
      "step": 3880
    },
    {
      "epoch": 1.728888888888889,
      "grad_norm": 0.9525362849235535,
      "learning_rate": 6.788888888888889e-06,
      "loss": 2.6665,
      "step": 3890
    },
    {
      "epoch": 1.7333333333333334,
      "grad_norm": 0.9722010493278503,
      "learning_rate": 6.677777777777779e-06,
      "loss": 2.6307,
      "step": 3900
    },
    {
      "epoch": 1.7333333333333334,
      "eval_loss": 2.7228500843048096,
      "eval_runtime": 196.1831,
      "eval_samples_per_second": 10.195,
      "eval_steps_per_second": 1.274,
      "step": 3900
    },
    {
      "epoch": 1.7377777777777776,
      "grad_norm": 0.8921759724617004,
      "learning_rate": 6.566666666666667e-06,
      "loss": 2.8312,
      "step": 3910
    },
    {
      "epoch": 1.7422222222222223,
      "grad_norm": 1.1494873762130737,
      "learning_rate": 6.4555555555555565e-06,
      "loss": 2.7392,
      "step": 3920
    },
    {
      "epoch": 1.7466666666666666,
      "grad_norm": 0.9633692502975464,
      "learning_rate": 6.344444444444445e-06,
      "loss": 2.7322,
      "step": 3930
    },
    {
      "epoch": 1.751111111111111,
      "grad_norm": 0.9401848912239075,
      "learning_rate": 6.2333333333333335e-06,
      "loss": 2.6666,
      "step": 3940
    },
    {
      "epoch": 1.7555555555555555,
      "grad_norm": 1.3203636407852173,
      "learning_rate": 6.1222222222222224e-06,
      "loss": 2.6688,
      "step": 3950
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.0634373426437378,
      "learning_rate": 6.011111111111111e-06,
      "loss": 2.8136,
      "step": 3960
    },
    {
      "epoch": 1.7644444444444445,
      "grad_norm": 1.1682002544403076,
      "learning_rate": 5.9e-06,
      "loss": 2.5683,
      "step": 3970
    },
    {
      "epoch": 1.7688888888888887,
      "grad_norm": 1.013975739479065,
      "learning_rate": 5.788888888888889e-06,
      "loss": 2.6658,
      "step": 3980
    },
    {
      "epoch": 1.7733333333333334,
      "grad_norm": 1.2085049152374268,
      "learning_rate": 5.677777777777778e-06,
      "loss": 2.7694,
      "step": 3990
    },
    {
      "epoch": 1.7777777777777777,
      "grad_norm": 0.9690364599227905,
      "learning_rate": 5.566666666666667e-06,
      "loss": 2.6722,
      "step": 4000
    },
    {
      "epoch": 1.7777777777777777,
      "eval_loss": 2.722587823867798,
      "eval_runtime": 196.26,
      "eval_samples_per_second": 10.191,
      "eval_steps_per_second": 1.274,
      "step": 4000
    }
  ],
  "logging_steps": 10,
  "max_steps": 4500,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 7.924705394688e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
