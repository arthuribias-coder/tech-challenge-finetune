{
  "best_metric": 2.788290500640869,
  "best_model_checkpoint": "./outputs/checkpoint-300",
  "epoch": 0.13333333333333333,
  "eval_steps": 100,
  "global_step": 300,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0044444444444444444,
      "grad_norm": 0.6385458707809448,
      "learning_rate": 4.9888888888888894e-05,
      "loss": 3.4474,
      "step": 10
    },
    {
      "epoch": 0.008888888888888889,
      "grad_norm": 0.5836634635925293,
      "learning_rate": 4.977777777777778e-05,
      "loss": 3.2499,
      "step": 20
    },
    {
      "epoch": 0.013333333333333334,
      "grad_norm": 0.5975626111030579,
      "learning_rate": 4.966666666666667e-05,
      "loss": 2.9499,
      "step": 30
    },
    {
      "epoch": 0.017777777777777778,
      "grad_norm": 0.5284260511398315,
      "learning_rate": 4.955555555555556e-05,
      "loss": 2.9841,
      "step": 40
    },
    {
      "epoch": 0.022222222222222223,
      "grad_norm": 0.4768317639827728,
      "learning_rate": 4.9444444444444446e-05,
      "loss": 2.8488,
      "step": 50
    },
    {
      "epoch": 0.02666666666666667,
      "grad_norm": 0.6019676923751831,
      "learning_rate": 4.933333333333334e-05,
      "loss": 2.8174,
      "step": 60
    },
    {
      "epoch": 0.03111111111111111,
      "grad_norm": 0.4315429627895355,
      "learning_rate": 4.922222222222222e-05,
      "loss": 2.8301,
      "step": 70
    },
    {
      "epoch": 0.035555555555555556,
      "grad_norm": 0.5725593566894531,
      "learning_rate": 4.9111111111111114e-05,
      "loss": 2.8291,
      "step": 80
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.5543215274810791,
      "learning_rate": 4.9e-05,
      "loss": 2.8156,
      "step": 90
    },
    {
      "epoch": 0.044444444444444446,
      "grad_norm": 0.4583193063735962,
      "learning_rate": 4.888888888888889e-05,
      "loss": 2.8502,
      "step": 100
    },
    {
      "epoch": 0.044444444444444446,
      "eval_loss": 2.8353183269500732,
      "eval_runtime": 197.5325,
      "eval_samples_per_second": 10.125,
      "eval_steps_per_second": 1.266,
      "step": 100
    },
    {
      "epoch": 0.04888888888888889,
      "grad_norm": 0.6037725210189819,
      "learning_rate": 4.8777777777777775e-05,
      "loss": 2.8819,
      "step": 110
    },
    {
      "epoch": 0.05333333333333334,
      "grad_norm": 0.6795234084129333,
      "learning_rate": 4.866666666666667e-05,
      "loss": 2.9167,
      "step": 120
    },
    {
      "epoch": 0.057777777777777775,
      "grad_norm": 0.674334704875946,
      "learning_rate": 4.855555555555556e-05,
      "loss": 2.7826,
      "step": 130
    },
    {
      "epoch": 0.06222222222222222,
      "grad_norm": 0.6613140106201172,
      "learning_rate": 4.844444444444445e-05,
      "loss": 2.8455,
      "step": 140
    },
    {
      "epoch": 0.06666666666666667,
      "grad_norm": 0.7885493040084839,
      "learning_rate": 4.8333333333333334e-05,
      "loss": 2.7365,
      "step": 150
    },
    {
      "epoch": 0.07111111111111111,
      "grad_norm": 0.8391779661178589,
      "learning_rate": 4.8222222222222225e-05,
      "loss": 2.7638,
      "step": 160
    },
    {
      "epoch": 0.07555555555555556,
      "grad_norm": 0.6468204855918884,
      "learning_rate": 4.811111111111111e-05,
      "loss": 2.7456,
      "step": 170
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.683377742767334,
      "learning_rate": 4.8e-05,
      "loss": 2.801,
      "step": 180
    },
    {
      "epoch": 0.08444444444444445,
      "grad_norm": 0.5992774963378906,
      "learning_rate": 4.7888888888888886e-05,
      "loss": 2.7839,
      "step": 190
    },
    {
      "epoch": 0.08888888888888889,
      "grad_norm": 0.6587018966674805,
      "learning_rate": 4.7777777777777784e-05,
      "loss": 2.8475,
      "step": 200
    },
    {
      "epoch": 0.08888888888888889,
      "eval_loss": 2.8036391735076904,
      "eval_runtime": 197.5629,
      "eval_samples_per_second": 10.123,
      "eval_steps_per_second": 1.265,
      "step": 200
    },
    {
      "epoch": 0.09333333333333334,
      "grad_norm": 0.6106796860694885,
      "learning_rate": 4.766666666666667e-05,
      "loss": 2.702,
      "step": 210
    },
    {
      "epoch": 0.09777777777777778,
      "grad_norm": 1.0709853172302246,
      "learning_rate": 4.755555555555556e-05,
      "loss": 2.6563,
      "step": 220
    },
    {
      "epoch": 0.10222222222222223,
      "grad_norm": 0.766156792640686,
      "learning_rate": 4.7444444444444445e-05,
      "loss": 2.7211,
      "step": 230
    },
    {
      "epoch": 0.10666666666666667,
      "grad_norm": 0.7021797895431519,
      "learning_rate": 4.7333333333333336e-05,
      "loss": 2.7997,
      "step": 240
    },
    {
      "epoch": 0.1111111111111111,
      "grad_norm": 0.7881563305854797,
      "learning_rate": 4.722222222222222e-05,
      "loss": 2.7492,
      "step": 250
    },
    {
      "epoch": 0.11555555555555555,
      "grad_norm": 0.7008208632469177,
      "learning_rate": 4.711111111111111e-05,
      "loss": 2.7347,
      "step": 260
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5889718532562256,
      "learning_rate": 4.7e-05,
      "loss": 2.7529,
      "step": 270
    },
    {
      "epoch": 0.12444444444444444,
      "grad_norm": 0.7305594682693481,
      "learning_rate": 4.6888888888888895e-05,
      "loss": 2.7243,
      "step": 280
    },
    {
      "epoch": 0.1288888888888889,
      "grad_norm": 0.7315137386322021,
      "learning_rate": 4.677777777777778e-05,
      "loss": 2.7451,
      "step": 290
    },
    {
      "epoch": 0.13333333333333333,
      "grad_norm": 0.7913298606872559,
      "learning_rate": 4.666666666666667e-05,
      "loss": 2.7776,
      "step": 300
    },
    {
      "epoch": 0.13333333333333333,
      "eval_loss": 2.788290500640869,
      "eval_runtime": 197.4899,
      "eval_samples_per_second": 10.127,
      "eval_steps_per_second": 1.266,
      "step": 300
    }
  ],
  "logging_steps": 10,
  "max_steps": 4500,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 5943529046016000.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
