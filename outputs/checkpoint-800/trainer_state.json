{
  "best_metric": 2.7616944313049316,
  "best_model_checkpoint": "./outputs/checkpoint-800",
  "epoch": 0.35555555555555557,
  "eval_steps": 100,
  "global_step": 800,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0044444444444444444,
      "grad_norm": 0.6385458707809448,
      "learning_rate": 4.9888888888888894e-05,
      "loss": 3.4474,
      "step": 10
    },
    {
      "epoch": 0.008888888888888889,
      "grad_norm": 0.5836634635925293,
      "learning_rate": 4.977777777777778e-05,
      "loss": 3.2499,
      "step": 20
    },
    {
      "epoch": 0.013333333333333334,
      "grad_norm": 0.5975626111030579,
      "learning_rate": 4.966666666666667e-05,
      "loss": 2.9499,
      "step": 30
    },
    {
      "epoch": 0.017777777777777778,
      "grad_norm": 0.5284260511398315,
      "learning_rate": 4.955555555555556e-05,
      "loss": 2.9841,
      "step": 40
    },
    {
      "epoch": 0.022222222222222223,
      "grad_norm": 0.4768317639827728,
      "learning_rate": 4.9444444444444446e-05,
      "loss": 2.8488,
      "step": 50
    },
    {
      "epoch": 0.02666666666666667,
      "grad_norm": 0.6019676923751831,
      "learning_rate": 4.933333333333334e-05,
      "loss": 2.8174,
      "step": 60
    },
    {
      "epoch": 0.03111111111111111,
      "grad_norm": 0.4315429627895355,
      "learning_rate": 4.922222222222222e-05,
      "loss": 2.8301,
      "step": 70
    },
    {
      "epoch": 0.035555555555555556,
      "grad_norm": 0.5725593566894531,
      "learning_rate": 4.9111111111111114e-05,
      "loss": 2.8291,
      "step": 80
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.5543215274810791,
      "learning_rate": 4.9e-05,
      "loss": 2.8156,
      "step": 90
    },
    {
      "epoch": 0.044444444444444446,
      "grad_norm": 0.4583193063735962,
      "learning_rate": 4.888888888888889e-05,
      "loss": 2.8502,
      "step": 100
    },
    {
      "epoch": 0.044444444444444446,
      "eval_loss": 2.8353183269500732,
      "eval_runtime": 197.5325,
      "eval_samples_per_second": 10.125,
      "eval_steps_per_second": 1.266,
      "step": 100
    },
    {
      "epoch": 0.04888888888888889,
      "grad_norm": 0.6037725210189819,
      "learning_rate": 4.8777777777777775e-05,
      "loss": 2.8819,
      "step": 110
    },
    {
      "epoch": 0.05333333333333334,
      "grad_norm": 0.6795234084129333,
      "learning_rate": 4.866666666666667e-05,
      "loss": 2.9167,
      "step": 120
    },
    {
      "epoch": 0.057777777777777775,
      "grad_norm": 0.674334704875946,
      "learning_rate": 4.855555555555556e-05,
      "loss": 2.7826,
      "step": 130
    },
    {
      "epoch": 0.06222222222222222,
      "grad_norm": 0.6613140106201172,
      "learning_rate": 4.844444444444445e-05,
      "loss": 2.8455,
      "step": 140
    },
    {
      "epoch": 0.06666666666666667,
      "grad_norm": 0.7885493040084839,
      "learning_rate": 4.8333333333333334e-05,
      "loss": 2.7365,
      "step": 150
    },
    {
      "epoch": 0.07111111111111111,
      "grad_norm": 0.8391779661178589,
      "learning_rate": 4.8222222222222225e-05,
      "loss": 2.7638,
      "step": 160
    },
    {
      "epoch": 0.07555555555555556,
      "grad_norm": 0.6468204855918884,
      "learning_rate": 4.811111111111111e-05,
      "loss": 2.7456,
      "step": 170
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.683377742767334,
      "learning_rate": 4.8e-05,
      "loss": 2.801,
      "step": 180
    },
    {
      "epoch": 0.08444444444444445,
      "grad_norm": 0.5992774963378906,
      "learning_rate": 4.7888888888888886e-05,
      "loss": 2.7839,
      "step": 190
    },
    {
      "epoch": 0.08888888888888889,
      "grad_norm": 0.6587018966674805,
      "learning_rate": 4.7777777777777784e-05,
      "loss": 2.8475,
      "step": 200
    },
    {
      "epoch": 0.08888888888888889,
      "eval_loss": 2.8036391735076904,
      "eval_runtime": 197.5629,
      "eval_samples_per_second": 10.123,
      "eval_steps_per_second": 1.265,
      "step": 200
    },
    {
      "epoch": 0.09333333333333334,
      "grad_norm": 0.6106796860694885,
      "learning_rate": 4.766666666666667e-05,
      "loss": 2.702,
      "step": 210
    },
    {
      "epoch": 0.09777777777777778,
      "grad_norm": 1.0709853172302246,
      "learning_rate": 4.755555555555556e-05,
      "loss": 2.6563,
      "step": 220
    },
    {
      "epoch": 0.10222222222222223,
      "grad_norm": 0.766156792640686,
      "learning_rate": 4.7444444444444445e-05,
      "loss": 2.7211,
      "step": 230
    },
    {
      "epoch": 0.10666666666666667,
      "grad_norm": 0.7021797895431519,
      "learning_rate": 4.7333333333333336e-05,
      "loss": 2.7997,
      "step": 240
    },
    {
      "epoch": 0.1111111111111111,
      "grad_norm": 0.7881563305854797,
      "learning_rate": 4.722222222222222e-05,
      "loss": 2.7492,
      "step": 250
    },
    {
      "epoch": 0.11555555555555555,
      "grad_norm": 0.7008208632469177,
      "learning_rate": 4.711111111111111e-05,
      "loss": 2.7347,
      "step": 260
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5889718532562256,
      "learning_rate": 4.7e-05,
      "loss": 2.7529,
      "step": 270
    },
    {
      "epoch": 0.12444444444444444,
      "grad_norm": 0.7305594682693481,
      "learning_rate": 4.6888888888888895e-05,
      "loss": 2.7243,
      "step": 280
    },
    {
      "epoch": 0.1288888888888889,
      "grad_norm": 0.7315137386322021,
      "learning_rate": 4.677777777777778e-05,
      "loss": 2.7451,
      "step": 290
    },
    {
      "epoch": 0.13333333333333333,
      "grad_norm": 0.7913298606872559,
      "learning_rate": 4.666666666666667e-05,
      "loss": 2.7776,
      "step": 300
    },
    {
      "epoch": 0.13333333333333333,
      "eval_loss": 2.788290500640869,
      "eval_runtime": 197.4899,
      "eval_samples_per_second": 10.127,
      "eval_steps_per_second": 1.266,
      "step": 300
    },
    {
      "epoch": 0.13777777777777778,
      "grad_norm": 0.672248125076294,
      "learning_rate": 4.6555555555555556e-05,
      "loss": 2.8238,
      "step": 310
    },
    {
      "epoch": 0.14222222222222222,
      "grad_norm": 0.6893551349639893,
      "learning_rate": 4.644444444444445e-05,
      "loss": 2.7119,
      "step": 320
    },
    {
      "epoch": 0.14666666666666667,
      "grad_norm": 0.7400459051132202,
      "learning_rate": 4.633333333333333e-05,
      "loss": 2.7798,
      "step": 330
    },
    {
      "epoch": 0.1511111111111111,
      "grad_norm": 1.0300168991088867,
      "learning_rate": 4.6222222222222224e-05,
      "loss": 2.7234,
      "step": 340
    },
    {
      "epoch": 0.15555555555555556,
      "grad_norm": 0.622245192527771,
      "learning_rate": 4.6111111111111115e-05,
      "loss": 2.7447,
      "step": 350
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.749061644077301,
      "learning_rate": 4.600000000000001e-05,
      "loss": 2.7392,
      "step": 360
    },
    {
      "epoch": 0.16444444444444445,
      "grad_norm": 1.0893040895462036,
      "learning_rate": 4.588888888888889e-05,
      "loss": 2.871,
      "step": 370
    },
    {
      "epoch": 0.1688888888888889,
      "grad_norm": 0.7031847834587097,
      "learning_rate": 4.577777777777778e-05,
      "loss": 2.7384,
      "step": 380
    },
    {
      "epoch": 0.17333333333333334,
      "grad_norm": 0.9796207547187805,
      "learning_rate": 4.566666666666667e-05,
      "loss": 2.7469,
      "step": 390
    },
    {
      "epoch": 0.17777777777777778,
      "grad_norm": 1.1894820928573608,
      "learning_rate": 4.555555555555556e-05,
      "loss": 2.7717,
      "step": 400
    },
    {
      "epoch": 0.17777777777777778,
      "eval_loss": 2.782315254211426,
      "eval_runtime": 197.5715,
      "eval_samples_per_second": 10.123,
      "eval_steps_per_second": 1.265,
      "step": 400
    },
    {
      "epoch": 0.18222222222222223,
      "grad_norm": 0.9657090902328491,
      "learning_rate": 4.5444444444444444e-05,
      "loss": 2.7223,
      "step": 410
    },
    {
      "epoch": 0.18666666666666668,
      "grad_norm": 0.9215372204780579,
      "learning_rate": 4.5333333333333335e-05,
      "loss": 2.801,
      "step": 420
    },
    {
      "epoch": 0.19111111111111112,
      "grad_norm": 0.8388105034828186,
      "learning_rate": 4.522222222222223e-05,
      "loss": 2.7478,
      "step": 430
    },
    {
      "epoch": 0.19555555555555557,
      "grad_norm": 0.8535682559013367,
      "learning_rate": 4.511111111111112e-05,
      "loss": 2.6471,
      "step": 440
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.9995908141136169,
      "learning_rate": 4.5e-05,
      "loss": 2.6696,
      "step": 450
    },
    {
      "epoch": 0.20444444444444446,
      "grad_norm": 0.701619029045105,
      "learning_rate": 4.4888888888888894e-05,
      "loss": 2.6829,
      "step": 460
    },
    {
      "epoch": 0.2088888888888889,
      "grad_norm": 0.7900257706642151,
      "learning_rate": 4.477777777777778e-05,
      "loss": 2.7647,
      "step": 470
    },
    {
      "epoch": 0.21333333333333335,
      "grad_norm": 0.7405385375022888,
      "learning_rate": 4.466666666666667e-05,
      "loss": 2.7003,
      "step": 480
    },
    {
      "epoch": 0.21777777777777776,
      "grad_norm": 0.7802812457084656,
      "learning_rate": 4.4555555555555555e-05,
      "loss": 2.7491,
      "step": 490
    },
    {
      "epoch": 0.2222222222222222,
      "grad_norm": 0.7782845497131348,
      "learning_rate": 4.4444444444444447e-05,
      "loss": 2.8225,
      "step": 500
    },
    {
      "epoch": 0.2222222222222222,
      "eval_loss": 2.7725062370300293,
      "eval_runtime": 197.2198,
      "eval_samples_per_second": 10.141,
      "eval_steps_per_second": 1.268,
      "step": 500
    },
    {
      "epoch": 0.22666666666666666,
      "grad_norm": 0.6806333661079407,
      "learning_rate": 4.433333333333334e-05,
      "loss": 2.7608,
      "step": 510
    },
    {
      "epoch": 0.2311111111111111,
      "grad_norm": 0.6650264263153076,
      "learning_rate": 4.422222222222222e-05,
      "loss": 2.8454,
      "step": 520
    },
    {
      "epoch": 0.23555555555555555,
      "grad_norm": 0.647793710231781,
      "learning_rate": 4.4111111111111114e-05,
      "loss": 2.8493,
      "step": 530
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.7477841377258301,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 2.6885,
      "step": 540
    },
    {
      "epoch": 0.24444444444444444,
      "grad_norm": 0.6355180740356445,
      "learning_rate": 4.388888888888889e-05,
      "loss": 2.7658,
      "step": 550
    },
    {
      "epoch": 0.24888888888888888,
      "grad_norm": 0.743603527545929,
      "learning_rate": 4.377777777777778e-05,
      "loss": 2.7571,
      "step": 560
    },
    {
      "epoch": 0.25333333333333335,
      "grad_norm": 0.7004106044769287,
      "learning_rate": 4.3666666666666666e-05,
      "loss": 2.73,
      "step": 570
    },
    {
      "epoch": 0.2577777777777778,
      "grad_norm": 0.8036758303642273,
      "learning_rate": 4.355555555555556e-05,
      "loss": 2.7492,
      "step": 580
    },
    {
      "epoch": 0.26222222222222225,
      "grad_norm": 0.9417545199394226,
      "learning_rate": 4.344444444444445e-05,
      "loss": 2.726,
      "step": 590
    },
    {
      "epoch": 0.26666666666666666,
      "grad_norm": 0.8402337431907654,
      "learning_rate": 4.3333333333333334e-05,
      "loss": 2.674,
      "step": 600
    },
    {
      "epoch": 0.26666666666666666,
      "eval_loss": 2.7687604427337646,
      "eval_runtime": 197.1542,
      "eval_samples_per_second": 10.144,
      "eval_steps_per_second": 1.268,
      "step": 600
    },
    {
      "epoch": 0.27111111111111114,
      "grad_norm": 0.7417306900024414,
      "learning_rate": 4.3222222222222226e-05,
      "loss": 2.7678,
      "step": 610
    },
    {
      "epoch": 0.27555555555555555,
      "grad_norm": 1.0891952514648438,
      "learning_rate": 4.311111111111111e-05,
      "loss": 2.7515,
      "step": 620
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.6318672895431519,
      "learning_rate": 4.3e-05,
      "loss": 2.8414,
      "step": 630
    },
    {
      "epoch": 0.28444444444444444,
      "grad_norm": 0.9144419431686401,
      "learning_rate": 4.2888888888888886e-05,
      "loss": 2.6959,
      "step": 640
    },
    {
      "epoch": 0.28888888888888886,
      "grad_norm": 0.7177309989929199,
      "learning_rate": 4.277777777777778e-05,
      "loss": 2.7571,
      "step": 650
    },
    {
      "epoch": 0.29333333333333333,
      "grad_norm": 0.788387656211853,
      "learning_rate": 4.266666666666667e-05,
      "loss": 2.7638,
      "step": 660
    },
    {
      "epoch": 0.29777777777777775,
      "grad_norm": 0.8486708998680115,
      "learning_rate": 4.255555555555556e-05,
      "loss": 2.6516,
      "step": 670
    },
    {
      "epoch": 0.3022222222222222,
      "grad_norm": 0.7327678799629211,
      "learning_rate": 4.2444444444444445e-05,
      "loss": 2.7269,
      "step": 680
    },
    {
      "epoch": 0.30666666666666664,
      "grad_norm": 0.8359125852584839,
      "learning_rate": 4.233333333333334e-05,
      "loss": 2.8246,
      "step": 690
    },
    {
      "epoch": 0.3111111111111111,
      "grad_norm": 0.7560226917266846,
      "learning_rate": 4.222222222222222e-05,
      "loss": 2.7814,
      "step": 700
    },
    {
      "epoch": 0.3111111111111111,
      "eval_loss": 2.7650961875915527,
      "eval_runtime": 198.6402,
      "eval_samples_per_second": 10.068,
      "eval_steps_per_second": 1.259,
      "step": 700
    },
    {
      "epoch": 0.31555555555555553,
      "grad_norm": 1.067901849746704,
      "learning_rate": 4.211111111111111e-05,
      "loss": 2.7116,
      "step": 710
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.9432044625282288,
      "learning_rate": 4.2e-05,
      "loss": 2.6898,
      "step": 720
    },
    {
      "epoch": 0.3244444444444444,
      "grad_norm": 0.8957403302192688,
      "learning_rate": 4.188888888888889e-05,
      "loss": 2.7443,
      "step": 730
    },
    {
      "epoch": 0.3288888888888889,
      "grad_norm": 0.6469542980194092,
      "learning_rate": 4.177777777777778e-05,
      "loss": 2.6894,
      "step": 740
    },
    {
      "epoch": 0.3333333333333333,
      "grad_norm": 0.8531420826911926,
      "learning_rate": 4.166666666666667e-05,
      "loss": 2.7056,
      "step": 750
    },
    {
      "epoch": 0.3377777777777778,
      "grad_norm": 0.8999106287956238,
      "learning_rate": 4.155555555555556e-05,
      "loss": 2.6939,
      "step": 760
    },
    {
      "epoch": 0.3422222222222222,
      "grad_norm": 0.7439743876457214,
      "learning_rate": 4.144444444444445e-05,
      "loss": 2.7058,
      "step": 770
    },
    {
      "epoch": 0.3466666666666667,
      "grad_norm": 0.8376057147979736,
      "learning_rate": 4.133333333333333e-05,
      "loss": 2.8228,
      "step": 780
    },
    {
      "epoch": 0.3511111111111111,
      "grad_norm": 0.8972124457359314,
      "learning_rate": 4.1222222222222224e-05,
      "loss": 2.8116,
      "step": 790
    },
    {
      "epoch": 0.35555555555555557,
      "grad_norm": 0.8277852535247803,
      "learning_rate": 4.111111111111111e-05,
      "loss": 2.6769,
      "step": 800
    },
    {
      "epoch": 0.35555555555555557,
      "eval_loss": 2.7616944313049316,
      "eval_runtime": 198.6423,
      "eval_samples_per_second": 10.068,
      "eval_steps_per_second": 1.259,
      "step": 800
    }
  ],
  "logging_steps": 10,
  "max_steps": 4500,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.5849410789376e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
