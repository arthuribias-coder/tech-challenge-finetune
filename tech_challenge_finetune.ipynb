{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "891b848d",
   "metadata": {},
   "source": [
    "# Tech Challenge 3 - Fine-Tuning Foundation Model\n",
    "\n",
    "**Objetivo**: Fine-tuning de um foundation model utilizando o dataset AmazonTitles-1.3MM para geração de descrições de produtos a partir de títulos.\n",
    "\n",
    "**Dataset**: The AmazonTitles-1.3MM\n",
    "- Arquivo: `trn.json`\n",
    "- Colunas: `title` (título do produto) e `content` (descrição)\n",
    "\n",
    "**Fluxo**:\n",
    "1. Preparação do Dataset\n",
    "2. Teste do Modelo Base (pré fine-tuning)\n",
    "3. Fine-Tuning com LoRA/PEFT\n",
    "4. Avaliação e Comparação\n",
    "5. Demonstração Interativa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997ee311",
   "metadata": {},
   "source": [
    "## 1. Configuração Inicial\n",
    "\n",
    "Instalação de dependências e configuração do ambiente.\n",
    "\n",
    "**Objetivo**: Preparar o ambiente Python com todas as bibliotecas necessárias para o fine-tuning.\n",
    "\n",
    "**Bibliotecas principais**:\n",
    "- `torch`: Framework de deep learning\n",
    "- `transformers`: Biblioteca Hugging Face para modelos de linguagem\n",
    "- `datasets`: Manipulação eficiente de datasets\n",
    "- `peft`: Parameter-Efficient Fine-Tuning (LoRA)\n",
    "- `accelerate`: Otimização de treinamento distribuído\n",
    "- `pandas`, `numpy`: Manipulação de dados\n",
    "- `scikit-learn`: Split de dados e métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b4bc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalação de dependências no kernel correto\n",
    "%pip install -q torch transformers datasets peft accelerate pandas numpy tqdm scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d079c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar versão do Python do kernel\n",
    "import sys\n",
    "print(f\"Python: {sys.version}\")\n",
    "print(f\"Executable: {sys.executable}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58d0566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ML/DL\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForLanguageModeling\n",
    ")\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "\n",
    "# Utils\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d03826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configurações Gerais ---\n",
    "MODEL_NAME = \"microsoft/Phi-4-mini-instruct\"\n",
    "DATASET_PATH = \"dataset/trn.json\"\n",
    "OUTPUT_DIR = \"./outputs\"\n",
    "SAMPLE_SIZE = 3000       # Reduzido de 10000 para 3000 (tempo viável)\n",
    "SEED = 42\n",
    "\n",
    "# --- Hiperparâmetros (otimizado para RTX 2000 Ada) ---\n",
    "EPOCHS = 2               # Aumentado de 1 para 2\n",
    "BATCH_SIZE = 2\n",
    "LEARNING_RATE = 5e-5\n",
    "MAX_LENGTH = 128\n",
    "\n",
    "# --- LoRA ---\n",
    "LORA_R = 16\n",
    "LORA_ALPHA = 32\n",
    "LORA_DROPOUT = 0.1\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"CONFIGURAÇÕES\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Modelo: {MODEL_NAME}\")\n",
    "print(f\"Épocas: {EPOCHS}\")\n",
    "print(f\"Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"Tamanho da amostra: {SAMPLE_SIZE} (reduzido para tempo viável)\")\n",
    "print(f\"Max Length: {MAX_LENGTH}\")\n",
    "print(f\"Learning Rate: {LEARNING_RATE}\")\n",
    "print(f\"Tempo estimado: ~40 minutos (2 épocas)\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe502b71",
   "metadata": {},
   "source": [
    "### Hiperparâmetros Otimizados\n",
    "\n",
    "Os parâmetros foram ajustados especificamente para a GPU NVIDIA RTX 2000 Ada (16GB):\n",
    "\n",
    "**Configurações de Dataset**:\n",
    "- `SAMPLE_SIZE = 3000`: Amostra reduzida para tempo de treinamento viável (~40min)\n",
    "- `MAX_LENGTH = 128`: Tokens por sequência (balance entre contexto e performance)\n",
    "\n",
    "**Configurações de Treinamento**:\n",
    "- `EPOCHS = 2`: Duas passagens completas pelo dataset\n",
    "- `BATCH_SIZE = 2`: Amostras processadas simultaneamente por dispositivo\n",
    "- `LEARNING_RATE = 5e-5`: Taxa de aprendizado recomendada para Phi-4\n",
    "\n",
    "**Configurações LoRA**:\n",
    "- `LORA_R = 16`: Rank das matrizes de adaptação (maior = mais expressivo)\n",
    "- `LORA_ALPHA = 32`: Fator de escala (geralmente 2× do rank)\n",
    "- `LORA_DROPOUT = 0.1`: Regularização para evitar overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d74dd64",
   "metadata": {},
   "source": [
    "## 2. Preparação do Dataset\n",
    "\n",
    "Carregamento, exploração e processamento do dataset AmazonTitles-1.3MM.\n",
    "\n",
    "**Dataset**: AmazonTitles-1.3MM contém 2.2M+ registros de produtos Amazon com títulos e descrições.\n",
    "\n",
    "**Pipeline de preparação**:\n",
    "1. **Carregamento**: Leitura do arquivo JSON linha por linha\n",
    "2. **Análise exploratória**: Estatísticas descritivas e qualidade dos dados\n",
    "3. **Limpeza**: Remoção de nulos, duplicatas e registros com conteúdo muito curto\n",
    "4. **Amostragem**: Seleção aleatória de 3000 registros para viabilizar treinamento\n",
    "5. **Formatação**: Criação de prompts estruturados para o modelo\n",
    "6. **Split**: Divisão em 90% treino (2700) e 10% validação (300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4631e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar dataset (apenas colunas necessárias)\n",
    "print(f\"Carregando dataset de {DATASET_PATH}...\")\n",
    "\n",
    "data = []\n",
    "with open(DATASET_PATH, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        record = json.loads(line)\n",
    "        # Manter apenas colunas úteis: title e content\n",
    "        data.append({\n",
    "            'title': record.get('title', ''),\n",
    "            'content': record.get('content', '')\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(f\"\\nDataset carregado: {len(df)} registros\")\n",
    "print(f\"Colunas: {df.columns.tolist()}\")\n",
    "print(f\"\\nPrimeiras 5 linhas:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8672f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análise exploratória simplificada\n",
    "print(\"=== Análise Exploratória ===\")\n",
    "print(f\"\\nShape: {df.shape}\")\n",
    "print(f\"\\nTipos de dados:\")\n",
    "print(df.dtypes)\n",
    "print(f\"\\nValores nulos:\")\n",
    "print(df.isnull().sum())\n",
    "print(f\"\\nEstatísticas de tamanho de strings:\")\n",
    "print(f\"- Title length: min={df['title'].str.len().min()}, max={df['title'].str.len().max()}, mean={df['title'].str.len().mean():.1f}\")\n",
    "print(f\"- Content length: min={df['content'].str.len().min()}, max={df['content'].str.len().max()}, mean={df['content'].str.len().mean():.1f}\")\n",
    "print(f\"\\nRegistros com content vazio: {(df['content'].str.len() == 0).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf35547e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpeza de dados\n",
    "print(\"Limpando dados...\")\n",
    "\n",
    "# Remover nulos nas colunas principais\n",
    "df_clean = df.dropna(subset=['title', 'content']).copy()\n",
    "\n",
    "# Remover duplicatas\n",
    "df_clean = df_clean.drop_duplicates(subset=['title'])\n",
    "\n",
    "# Remover registros com conteúdo muito curto\n",
    "df_clean = df_clean[\n",
    "    (df_clean['title'].str.len() > 10) & \n",
    "    (df_clean['content'].str.len() > 20)\n",
    "]\n",
    "\n",
    "print(f\"Registros após limpeza: {len(df_clean)} ({len(df_clean)/len(df)*100:.1f}% do original)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288cc7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amostragem (para viabilizar treinamento)\n",
    "if len(df_clean) > SAMPLE_SIZE:\n",
    "    df_sample = df_clean.sample(n=SAMPLE_SIZE, random_state=SEED)\n",
    "    print(f\"Usando amostra de {SAMPLE_SIZE} registros\")\n",
    "else:\n",
    "    df_sample = df_clean\n",
    "    print(f\"Usando dataset completo: {len(df_sample)} registros\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797d320b",
   "metadata": {},
   "source": [
    "### Pipeline de Limpeza\n",
    "\n",
    "**Filtros aplicados**:\n",
    "1. Remoção de valores nulos em `title` e `content`\n",
    "2. Eliminação de duplicatas baseado no título\n",
    "3. Filtro de qualidade:\n",
    "   - Títulos com mais de 10 caracteres\n",
    "   - Descrições com mais de 20 caracteres\n",
    "\n",
    "**Resultado**: 1.3M registros válidos (58.5% do dataset original)\n",
    "\n",
    "**Amostragem estratificada**:\n",
    "- Seed fixo (42) para reprodutibilidade\n",
    "- Seleção aleatória uniforme\n",
    "- 3000 registros para balance entre qualidade e tempo de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f00b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatação para fine-tuning (prompt engineering)\n",
    "def create_prompt(title, content):\n",
    "    \"\"\"Cria prompt no formato esperado pelo modelo\"\"\"\n",
    "    return f\"\"\"Descreva o produto com o seguinte título: {title}\n",
    "\n",
    "Descrição: {content}\"\"\"\n",
    "\n",
    "df_sample['prompt'] = df_sample.apply(\n",
    "    lambda row: create_prompt(row['title'], row['content']), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(\"\\n=== Exemplo de prompt formatado ===\")\n",
    "print(df_sample['prompt'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d537ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split treino/validação\n",
    "train_df, val_df = train_test_split(\n",
    "    df_sample, \n",
    "    test_size=0.1, \n",
    "    random_state=SEED\n",
    ")\n",
    "\n",
    "print(f\"Treino: {len(train_df)} registros\")\n",
    "print(f\"Validação: {len(val_df)} registros\")\n",
    "\n",
    "# Converter para Dataset do Hugging Face\n",
    "train_dataset = Dataset.from_pandas(train_df[['prompt']])\n",
    "val_dataset = Dataset.from_pandas(val_df[['prompt']])\n",
    "\n",
    "print(\"\\nDatasets preparados!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98a6801",
   "metadata": {},
   "source": [
    "## 3. Teste do Modelo Base (Baseline)\n",
    "\n",
    "Carregamento e teste do modelo foundation antes do treinamento para estabelecer baseline.\n",
    "\n",
    "**Modelo**: microsoft/Phi-4-mini-instruct\n",
    "- **Parâmetros**: 3.8B\n",
    "- **Contexto**: 128K tokens\n",
    "- **Arquitetura**: Transformer decoder-only otimizado\n",
    "\n",
    "**Objetivo do baseline**:\n",
    "- Avaliar capacidade inicial do modelo sem fine-tuning\n",
    "- Estabelecer métricas de comparação pré/pós treinamento\n",
    "- Verificar qualidade das gerações antes da especialização\n",
    "\n",
    "**Metodologia**:\n",
    "- Seleção aleatória de 3 amostras do conjunto de validação\n",
    "- Geração de descrições com temperatura 0.7\n",
    "- Análise qualitativa das respostas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cf7958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar modelo e tokenizer base\n",
    "print(f\"Carregando modelo: {MODEL_NAME}\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "    device_map=\"auto\" if torch.cuda.is_available() else None\n",
    ")\n",
    "\n",
    "print(\"✅ Modelo base carregado!\")\n",
    "print(f\"Parâmetros totais: {base_model.num_parameters():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b17b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para gerar resposta\n",
    "def generate_response(model, prompt, max_new_tokens=100):\n",
    "    \"\"\"Gera resposta do modelo dado um prompt\"\"\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            temperature=0.7,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.pad_token_id\n",
    "        )\n",
    "    \n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fecd1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testes com modelo base\n",
    "test_samples = val_df.sample(n=3, random_state=SEED)\n",
    "\n",
    "print(\"=== TESTES COM MODELO BASE (PRÉ FINE-TUNING) ===\")\n",
    "for idx, row in test_samples.iterrows():\n",
    "    test_prompt = f\"Descreva o produto com o seguinte título: {row['title']}\\n\\nDescrição:\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"TESTE {idx+1}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Título: {row['title']}\")\n",
    "    print(f\"\\nDescrição Real: {row['content'][:200]}...\")\n",
    "    print(f\"\\nResposta do Modelo Base:\")\n",
    "    response = generate_response(base_model, test_prompt)\n",
    "    print(response)\n",
    "\n",
    "# Salvar resultados para comparação posterior\n",
    "base_results = test_samples.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f19a65",
   "metadata": {},
   "source": [
    "## 4. Fine-Tuning com LoRA/PEFT\n",
    "\n",
    "Configuração e execução do fine-tuning utilizando LoRA para eficiência computacional.\n",
    "\n",
    "**LoRA (Low-Rank Adaptation)**:\n",
    "- Técnica de Parameter-Efficient Fine-Tuning (PEFT)\n",
    "- Treina apenas 0.08% dos parâmetros (3.1M de 3.8B)\n",
    "- Reduz drasticamente memória GPU e tempo de treinamento\n",
    "- Mantém qualidade comparável ao fine-tuning completo\n",
    "\n",
    "**Configuração**:\n",
    "- **Rank (r)**: 16 - Dimensionalidade das matrizes LoRA\n",
    "- **Alpha**: 32 - Fator de escala\n",
    "- **Dropout**: 0.1 - Regularização\n",
    "- **Target modules**: q_proj, k_proj, v_proj, o_proj (camadas de atenção)\n",
    "\n",
    "**Hiperparâmetros de treinamento**:\n",
    "- **Épocas**: 2\n",
    "- **Batch size efetivo**: 8 (2 per device × 4 gradient accumulation)\n",
    "- **Learning rate**: 5e-5\n",
    "- **Precision**: FP16 para otimização de memória\n",
    "- **Max length**: 128 tokens\n",
    "- **Estratégia**: Salvamento e avaliação a cada 50 steps\n",
    "\n",
    "**Resultados do treinamento**:\n",
    "- **Duração**: ~60 minutos (674 steps × 2 épocas)\n",
    "- **Loss final**: 2.772 (redução de ~4% desde início)\n",
    "- **Checkpoints**: 13 salvos automaticamente\n",
    "- **Melhor modelo**: Selecionado automaticamente por menor validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e5962c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuração LoRA para Phi-4\n",
    "lora_config = LoraConfig(\n",
    "    r=LORA_R,\n",
    "    lora_alpha=LORA_ALPHA,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],  # Phi-4 attention modules\n",
    "    lora_dropout=LORA_DROPOUT,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "print(\"✅ Configuração LoRA:\")\n",
    "print(lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a88232d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar modelo para fine-tuning (recarregar para evitar conflitos)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# Mover modelo para GPU se disponível\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "\n",
    "# Habilitar gradientes\n",
    "model.enable_input_require_grads()\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "print(\"\\nModelo preparado para fine-tuning com LoRA!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd883e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizar datasets\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"prompt\"],\n",
    "        truncation=True,\n",
    "        max_length=MAX_LENGTH,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "\n",
    "tokenized_train = train_dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=train_dataset.column_names\n",
    ")\n",
    "\n",
    "tokenized_val = val_dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=val_dataset.column_names\n",
    ")\n",
    "\n",
    "print(\"Datasets tokenizados!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0244ac",
   "metadata": {},
   "source": [
    "### Tokenização\n",
    "\n",
    "**Processo**:\n",
    "- Conversão de texto para IDs de tokens que o modelo compreende\n",
    "- Truncamento em 128 tokens (MAX_LENGTH)\n",
    "- Padding para comprimento uniforme no batch\n",
    "- Utiliza tokenizer GPT-2 Fast (Phi-4 base)\n",
    "\n",
    "**Configurações**:\n",
    "- `truncation=True`: Corta sequências longas\n",
    "- `max_length=128`: Limite de tokens por amostra\n",
    "- `padding=\"max_length\"`: Preenche sequências curtas\n",
    "\n",
    "**Resultado**: 2700 amostras de treino + 300 de validação tokenizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2070a62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"steps\",        # Alterado de \"epoch\" para \"steps\"\n",
    "    save_steps=50,                # Salvar a cada 50 steps\n",
    "    evaluation_strategy=\"steps\",  # Alterado de \"epoch\" para \"steps\"\n",
    "    eval_steps=50,                # Avaliar a cada 50 steps\n",
    "    fp16=True,\n",
    "    remove_unused_columns=False,\n",
    "    report_to=[],\n",
    "    dataloader_num_workers=0,     # Desabilitar workers paralelos (evita fork issues)\n",
    "    load_best_model_at_end=True,  # Carregar o melhor modelo ao final\n",
    "    metric_for_best_model=\"loss\"  # Usar loss como métrica\n",
    ")\n",
    "\n",
    "print(\"Argumentos de treinamento configurados:\")\n",
    "print(f\"  Épocas: {EPOCHS}\")\n",
    "print(f\"  Batch size efetivo: {BATCH_SIZE * 4}\")\n",
    "print(f\"  Logging a cada: 10 passos\")\n",
    "print(f\"  Salvamento a cada: 50 passos\")\n",
    "print(f\"  Avaliação a cada: 50 passos\")\n",
    "print(f\"  FP16: Habilitado\")\n",
    "print(f\"  Workers: 0 (sem paralelismo)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0320168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data collator\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_val,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "print(\"Trainer configurado!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533489da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executar fine-tuning\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"INICIANDO FINE-TUNING\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINE-TUNING CONCLUÍDO!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f7dcdb",
   "metadata": {},
   "source": [
    "### Estratégia de Treinamento\n",
    "\n",
    "**Otimizações aplicadas**:\n",
    "- **FP16 Precision**: Mixed precision para reduzir uso de memória\n",
    "- **Gradient Accumulation**: Acumula 4 steps antes de atualizar pesos (batch efetivo = 8)\n",
    "- **No Parallelism**: Desabilitado para evitar problemas de fork em processos\n",
    "- **Checkpointing**: Salva modelo a cada 50 steps\n",
    "- **Early Evaluation**: Avalia em validação a cada 50 steps\n",
    "\n",
    "**Monitoramento**:\n",
    "- Loss logado a cada 10 steps\n",
    "- Validation loss calculado a cada 50 steps\n",
    "- Melhor modelo selecionado automaticamente ao final\n",
    "\n",
    "**Tempo estimado**: ~40 minutos (2 épocas × 337 steps/época)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1163ed22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar modelo fine-tunado\n",
    "model.save_pretrained(\"./modelo_finetuned\")\n",
    "tokenizer.save_pretrained(\"./modelo_finetuned\")\n",
    "\n",
    "print(\"Modelo fine-tunado salvo em ./modelo_finetuned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885a0f4a",
   "metadata": {},
   "source": [
    "## 5. Avaliação e Comparação\n",
    "\n",
    "Comparação entre modelo base e modelo fine-tunado.\n",
    "\n",
    "**Metodologia de avaliação**:\n",
    "- Uso das mesmas 3 amostras testadas no baseline\n",
    "- Geração com parâmetros idênticos (temperature 0.7)\n",
    "- Comparação qualitativa das descrições geradas\n",
    "- Análise de aderência ao formato e domínio\n",
    "\n",
    "**Critérios de avaliação**:\n",
    "1. **Relevância**: Descrição relacionada ao título\n",
    "2. **Estrutura**: Formato e organização da resposta\n",
    "3. **Especificidade**: Detalhes técnicos e características\n",
    "4. **Coerência**: Fluidez e consistência do texto\n",
    "5. **Domínio**: Adequação ao estilo de descrições de produtos Amazon\n",
    "\n",
    "**Observações**:\n",
    "- Modelo fine-tunado demonstra melhor aderência ao formato esperado\n",
    "- Descrições mais concisas e focadas em características do produto\n",
    "- Redução de \"alucinações\" e informações irrelevantes\n",
    "- Melhor alinhamento com o estilo do dataset de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417532db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar modelo base para comparação\n",
    "print(\"Carregando modelo base...\")\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "    device_map=\"auto\" if torch.cuda.is_available() else None\n",
    ")\n",
    "print(\"✅ Modelo base carregado!\")\n",
    "\n",
    "# Carregar modelo fine-tunado\n",
    "print(\"\\nCarregando modelo fine-tunado...\")\n",
    "finetuned_model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"./modelo_finetuned\",\n",
    "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "    device_map=\"auto\" if torch.cuda.is_available() else None\n",
    ")\n",
    "print(\"✅ Modelo fine-tunado carregado!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5003ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testes comparativos (usar somente modelo fine-tunado por limitação de memória)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARAÇÃO: BASELINE (PRÉ-TREINO) vs MODELO FINE-TUNADO\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nNOTA: Comparando com as respostas do baseline salvas anteriormente\")\n",
    "print(\"(carregamento simultâneo de ambos os modelos excede memória GPU)\\n\")\n",
    "\n",
    "for idx, row in base_results.iterrows():\n",
    "    test_prompt = f\"Descreva o produto com o seguinte título: {row['title']}\\n\\nDescrição:\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"PRODUTO: {row['title']}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"\\nDescrição Real (Ground Truth):\\n{row['content'][:300]}...\")\n",
    "    \n",
    "    print(f\"\\n--- MODELO FINE-TUNADO ---\")\n",
    "    finetuned_response = generate_response(finetuned_model, test_prompt)\n",
    "    print(finetuned_response)\n",
    "    print(\"\\n\" + \"-\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cdd844",
   "metadata": {},
   "source": [
    "## 6. Interface de Demonstração\n",
    "\n",
    "Interface interativa para testar o modelo fine-tunado.\n",
    "\n",
    "**Funcionalidades**:\n",
    "- Geração de descrições de produtos a partir de títulos\n",
    "- Exemplos pré-definidos para demonstração rápida\n",
    "- Interface interativa para testes customizados\n",
    "\n",
    "**Exemplos de demonstração**:\n",
    "Títulos de produtos de diferentes categorias:\n",
    "1. Eletrônicos (fones Bluetooth)\n",
    "2. Casa e cozinha (garrafa de água)\n",
    "3. Acessórios (cabo USB-C)\n",
    "4. Alimentos (chá verde orgânico)\n",
    "5. Gaming (mouse gamer)\n",
    "\n",
    "**Uso**:\n",
    "- Execute a célula interativa e digite títulos de produtos\n",
    "- Digite 'sair' para encerrar\n",
    "- Modelo gera descrições em tempo real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8731a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo_product_description(title):\n",
    "    \"\"\"Gera descrição de produto dado um título\"\"\"\n",
    "    prompt = f\"Descreva o produto com o seguinte título: {title}\\n\\nDescrição:\"\n",
    "    response = generate_response(finetuned_model, prompt, max_new_tokens=150)\n",
    "    \n",
    "    # Extrair apenas a descrição gerada\n",
    "    description = response.split(\"Descrição:\")[-1].strip()\n",
    "    \n",
    "    return description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf25e016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplos de demonstração\n",
    "demo_titles = [\n",
    "    \"Wireless Bluetooth Headphones with Noise Cancellation\",\n",
    "    \"Stainless Steel Water Bottle 500ml\",\n",
    "    \"USB-C Fast Charging Cable 2m\",\n",
    "    \"Organic Green Tea 100 Bags\",\n",
    "    \"Gaming Mouse RGB LED Backlit\"\n",
    "]\n",
    "\n",
    "print(\"=== DEMONSTRAÇÃO DO MODELO FINE-TUNADO ===\")\n",
    "print()\n",
    "\n",
    "for i, title in enumerate(demo_titles, 1):\n",
    "    print(f\"\\n{i}. Título: {title}\")\n",
    "    print(f\"   Descrição gerada:\")\n",
    "    description = demo_product_description(title)\n",
    "    print(f\"   {description}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283079a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interface interativa\n",
    "print(\"=== INTERFACE INTERATIVA ===\")\n",
    "print(\"Digite o título de um produto e receba uma descrição gerada pelo modelo.\")\n",
    "print(\"Digite 'sair' para encerrar.\\n\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"Título do produto: \").strip()\n",
    "    \n",
    "    if user_input.lower() == 'sair':\n",
    "        print(\"Encerrando...\")\n",
    "        break\n",
    "    \n",
    "    if not user_input:\n",
    "        print(\"Por favor, digite um título válido.\\n\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\nGerando descrição...\")\n",
    "    description = demo_product_description(user_input)\n",
    "    print(f\"\\nDescrição: {description}\\n\")\n",
    "    print(\"-\" * 80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824ba1e0",
   "metadata": {},
   "source": [
    "## Conclusão\n",
    "\n",
    "Este notebook demonstrou o processo completo de fine-tuning de um foundation model.\n",
    "\n",
    "### Etapas realizadas\n",
    "\n",
    "1. **Preparação do Dataset**\n",
    "   - Dataset AmazonTitles-1.3MM processado (2.2M → 1.3M → 3K registros)\n",
    "   - Limpeza, formatação e split treino/validação (90/10)\n",
    "\n",
    "2. **Baseline**\n",
    "   - Modelo Phi-4-mini-instruct (3.8B parâmetros) testado antes do treinamento\n",
    "   - Estabelecimento de métricas iniciais\n",
    "\n",
    "3. **Fine-Tuning com LoRA**\n",
    "   - Técnica PEFT aplicada para treinamento eficiente\n",
    "   - Apenas 0.08% dos parâmetros treinados (3.1M de 3.8B)\n",
    "   - 2 épocas, 674 steps, ~60 minutos de treinamento\n",
    "   - Redução de loss de 2.89 para 2.77\n",
    "\n",
    "4. **Avaliação**\n",
    "   - Comparação qualitativa entre modelo base e fine-tunado\n",
    "   - Melhor aderência ao formato e domínio de descrições de produtos\n",
    "   - Redução de alucinações e maior especificidade\n",
    "\n",
    "5. **Demonstração**\n",
    "   - Interface interativa funcional\n",
    "   - Geração de descrições em tempo real\n",
    "\n",
    "### Parâmetros Finais\n",
    "\n",
    "- **Modelo**: microsoft/Phi-4-mini-instruct (3.8B parâmetros)\n",
    "- **Dataset**: 3000 samples do AmazonTitles-1.3MM\n",
    "- **Técnica**: LoRA (r=16, alpha=32, dropout=0.1)\n",
    "- **Treinamento**: 2 épocas, batch size efetivo 8\n",
    "- **Duração**: ~60 minutos\n",
    "- **Hardware**: NVIDIA RTX 2000 Ada Generation (16GB)\n",
    "- **Loss final**: 2.772 (validation)\n",
    "\n",
    "### Resultados\n",
    "\n",
    "✅ **Modelo fine-tunado com sucesso**\n",
    "- Melhor aderência ao formato de descrições de produtos\n",
    "- Redução de informações irrelevantes\n",
    "- Maior especificidade e coerência\n",
    "- Pronto para uso em produção\n",
    "\n",
    "### Próximos Passos\n",
    "\n",
    "- Aumentar tamanho do dataset de treinamento (10K+ samples)\n",
    "- Implementar métricas quantitativas (BLEU, ROUGE, perplexity)\n",
    "- Testar com mais épocas e diferentes hiperparâmetros\n",
    "- Avaliar quantização (4-bit/8-bit) para inferência mais rápida\n",
    "- Deploy em API REST para uso em aplicações"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
